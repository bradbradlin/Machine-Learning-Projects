{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bradbradlin/Machine-Learning-Projects/blob/main/Speech_Emotion_Recognition_(Train)_TRILL_19_%2B_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CsHv7KgSR8e"
      },
      "source": [
        "2020/7/20\n",
        "\n",
        "https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\n",
        "https://towardsdatascience.com/how-to-build-efficient-audio-data-pipelines-with-tensorflow-2-0-b3133474c3c1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx7_47HYSR8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d757115a-5eee-4ae8-9454-496fe8bade5f"
      },
      "source": [
        "import os, glob, pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import wave\n",
        "import struct\n",
        "import resampy\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFFftUsdTjGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "7847477b-a3f9-4b16-e89b-f3e2c9330223"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs2Epr8-TrRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4460ac9-f799-497e-edb4-4ae97dd5f574"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/Audio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/AI trading project'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eYm8d_mSR8k"
      },
      "source": [
        "#DataFlair - Emotions in the RAVDESS dataset\n",
        "emotions={\n",
        "  'n':'neutral',\n",
        "#  '02':'calm',\n",
        "  'h':'happy',\n",
        "  'sa':'sad',\n",
        "  'a':'angry',\n",
        "  'f':'fearful',\n",
        "  'd':'disgust',\n",
        "  'su':'surprised'\n",
        "}\n",
        "#DataFlair - Emotions to observe\n",
        "observed_emotions=['angry','neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNfPUk7JSR8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2df0a9ae-a79c-45b1-e2e2-af035c1f996c"
      },
      "source": [
        "# Load TRILL embedding\n",
        "x_a = pickle.load( open( \"X_emb_layer19.pkl\", \"rb\" ) )\n",
        "x_b = pickle.load( open( \"X_emb_layer19_1000.pkl\", \"rb\" ) )\n",
        "x_c = pickle.load( open( \"X_emb_layer19_2000.pkl\", \"rb\" ) )\n",
        "y = pickle.load( open( \"label.pkl\", \"rb\" ) )\n",
        "\n",
        "print(len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFhxly84SR8t",
        "outputId": "9da8ce74-3ebb-477b-abb2-837daf5a84e2"
      },
      "source": [
        "x_a[0].numpy().reshape(-1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(245760,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMPcNSYySR8y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b44bf909-7166-420a-a57a-3b748344668d"
      },
      "source": [
        "x = []\n",
        "fix_length = 245760\n",
        "for i in x_a:\n",
        "    interm = tf.reshape(i, [-1])\n",
        "    if len(interm) < fix_length:\n",
        "        while len(interm) < fix_length:\n",
        "            interm = tf.concat([interm, interm], 0)\n",
        "    interm = interm[:fix_length]\n",
        "    x.append(interm)\n",
        "print(len(x))\n",
        "\n",
        "for i in x_b:\n",
        "    interm = tf.reshape(i, [-1])\n",
        "    if len(interm) < fix_length:\n",
        "        while len(interm) < fix_length:\n",
        "            interm = tf.concat([interm, interm], 0)\n",
        "    interm = interm[:fix_length]\n",
        "    x.append(interm)\n",
        "print(len(x))\n",
        "\n",
        "for i in x_c:\n",
        "    interm = tf.reshape(i, [-1])\n",
        "    if len(interm) < fix_length:\n",
        "        while len(interm) < fix_length:\n",
        "            interm = tf.concat([interm, interm], 0)\n",
        "    interm = interm[:fix_length]\n",
        "    x.append(interm)\n",
        "print(len(x))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88eyIZKlSR84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "474826a9-50d6-4335-839d-f8e61ebfe9fb"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, \n",
        "                                                 y, \n",
        "                                                 train_size=0.75, \n",
        "                                                 random_state=20)\n",
        "print(len(x_train), len(x_test))\n",
        "print(len(y_train), len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2502 835\n",
            "2502 835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEAyQPidSR88"
      },
      "source": [
        "### Fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmFncxprSR89"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Activation,Dropout, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ReduceLROnPlateau,\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    TensorBoard\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq08UZ4fSR9A"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "data_size = len(y_train)\n",
        "def _input_fn(x,y):\n",
        "    ds=tf.data.Dataset.from_tensor_slices((x,y))\n",
        "    ds=ds.shuffle(buffer_size=data_size)\n",
        "    ds = ds.repeat()  \n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFuJqpR-SR9D"
      },
      "source": [
        "# importing one hot encoder from sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "\n",
        "# creating one hot encoder object by default \n",
        "# entire data passed is one hot encoded \n",
        "onehotencoder = OneHotEncoder() \n",
        "\n",
        "y_train1 = onehotencoder.fit_transform(np.array(y_train).reshape(-1, 1)).toarray() \n",
        "y_test1 = onehotencoder.fit_transform(np.array(y_test).reshape(-1, 1)).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljqLKJaISR9G"
      },
      "source": [
        "train_ds2 = _input_fn(x_train, y_train1)\n",
        "val_ds2 = _input_fn(x_test, y_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGwo4SrgSR9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5b358628-0ca8-4690-b949-651b45005dcf"
      },
      "source": [
        "for example in train_ds2.take(1):\n",
        "    print(example[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.01985281  0.22948861 -0.22332656 ... -0.08037344 -0.15773186\n",
            "   0.09650982]\n",
            " [ 0.18867767  0.23138337 -0.0474422  ... -0.01412479 -0.19312967\n",
            "   0.07673208]\n",
            " [-0.29067785  0.13682337 -0.01023724 ... -0.0324953  -0.85322803\n",
            "   0.13276677]\n",
            " ...\n",
            " [ 0.078351    0.3146279  -0.02084058 ...  0.02213127 -0.29095343\n",
            "   0.47578004]\n",
            " [ 0.00175161 -0.00256302 -0.14296472 ... -0.03194676 -0.1560428\n",
            "   0.08011178]\n",
            " [ 0.1604246   0.22687659 -0.04744163 ... -0.03378016 -0.17951378\n",
            "   0.10858013]], shape=(16, 245760), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl5rWt6hSR9M"
      },
      "source": [
        "model3 = Sequential()\n",
        "#model3.add(Flatten(input_shape=(x_train_em.shape[1],1)))\n",
        "model3.add(Dense(100, input_shape=(x_train[0].shape[0],))) #1\n",
        "model3.add(Dense(80)) #2\n",
        "model3.add(Dense(60)) #3\n",
        "model3.add(Dense(40)) #4\n",
        "model3.add(Dense(20)) #5\n",
        "model3.add(Dense(len(observed_emotions))) #6\n",
        "model3.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7ncP_jxSR9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "06fc897b-3f6b-43d3-80f4-c968374c4639"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               24576100  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 80)                8080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 60)                4860      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 40)                2440      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 42        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 24,592,342\n",
            "Trainable params: 24,592,342\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRTWbFg4SR9T"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-6)\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dCuCk8HSR9X"
      },
      "source": [
        "checkpoint_path = \"model\\\\VGGish_NN_emotion_{epoch}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "#create a callback\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                save_weights_only=True,\n",
        "#                                                verbose=1,)\n",
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "cp_callbacks = [\n",
        "    ReduceLROnPlateau(verbose=1),\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ModelCheckpoint('checkpoints/TRILL_FCN_layer19_{epoch}.tf',\n",
        "                    verbose=1, save_weights_only=True),\n",
        "    TensorBoard(log_dir='logs')\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Egw9QsSR9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "168dcec8-fafc-4dd8-b8e0-b94c4bace06c"
      },
      "source": [
        "#import datetime\n",
        "#!rm -rf ./logs/\n",
        "#log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "history = model3.fit(train_ds2, \n",
        "                    epochs=10,\n",
        "                    steps_per_epoch=10,\n",
        "                    validation_steps=4,\n",
        "                    validation_data=val_ds2,\n",
        "                    callbacks=cp_callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9812\n",
            "Epoch 00001: saving model to checkpoints/TRILL_FCN_layer19_1.tf\n",
            "10/10 [==============================] - 6s 598ms/step - loss: 0.0785 - accuracy: 0.9812 - val_loss: 0.3701 - val_accuracy: 0.8906 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9688\n",
            "Epoch 00002: saving model to checkpoints/TRILL_FCN_layer19_2.tf\n",
            "10/10 [==============================] - 5s 545ms/step - loss: 0.0708 - accuracy: 0.9688 - val_loss: 0.2788 - val_accuracy: 0.9219 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9438\n",
            "Epoch 00003: saving model to checkpoints/TRILL_FCN_layer19_3.tf\n",
            "10/10 [==============================] - 6s 566ms/step - loss: 0.1373 - accuracy: 0.9438 - val_loss: 0.3486 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9250\n",
            "Epoch 00004: saving model to checkpoints/TRILL_FCN_layer19_4.tf\n",
            "10/10 [==============================] - 6s 593ms/step - loss: 0.1662 - accuracy: 0.9250 - val_loss: 0.0782 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9500\n",
            "Epoch 00005: saving model to checkpoints/TRILL_FCN_layer19_5.tf\n",
            "10/10 [==============================] - 5s 503ms/step - loss: 0.1598 - accuracy: 0.9500 - val_loss: 0.1180 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9312\n",
            "Epoch 00006: saving model to checkpoints/TRILL_FCN_layer19_6.tf\n",
            "10/10 [==============================] - 5s 516ms/step - loss: 0.2010 - accuracy: 0.9312 - val_loss: 0.3871 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9688\n",
            "Epoch 00007: saving model to checkpoints/TRILL_FCN_layer19_7.tf\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.0964 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9563\n",
            "Epoch 00008: saving model to checkpoints/TRILL_FCN_layer19_8.tf\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.1197 - accuracy: 0.9563 - val_loss: 0.2771 - val_accuracy: 0.8906 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9688\n",
            "Epoch 00009: saving model to checkpoints/TRILL_FCN_layer19_9.tf\n",
            "10/10 [==============================] - 5s 465ms/step - loss: 0.1615 - accuracy: 0.9688 - val_loss: 0.1847 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGeJHdR_SR9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89d6df5e-532d-49e9-af14-74fe144db9ef"
      },
      "source": [
        "model3.load_weights('checkpoints/TRILL_FCN_layer19_4.tf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f70ca9a08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU5Ku697SR9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d6d8fee-7164-4988-9641-46e824e0d906"
      },
      "source": [
        "#Confution Matrix\n",
        "sizes = 100\n",
        "y_true = []\n",
        "for example in train_ds2.take(sizes):\n",
        "    y_true.append(pd.DataFrame(example[1].numpy(),\n",
        "                              columns=onehotencoder.categories_[0]).idxmax(1))\n",
        "\n",
        "y_true = np.array(y_true).reshape(-1)\n",
        "Y_pred = model3.predict(val_ds2, steps = sizes)\n",
        "y_pred = pd.DataFrame(Y_pred, columns=onehotencoder.categories_[0]).idxmax(1)\n",
        "print(y_true.shape)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1600,)\n",
            "(1600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_t9_sPKSR9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "845999ef-4d16-4963-d84f-32f9c7482ef3"
      },
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "accuracy=accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 48.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQL11XWrSR9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "ce5c7873-c887-4dd1-cb43-f87391f10dc5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "labels = observed_emotions\n",
        "cm = confusion_matrix(y_true, y_pred, labels)\n",
        "cm_df = pd.DataFrame(cm, labels, labels)\n",
        "print(cm_df)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "sns.heatmap(cm_df, annot=True, cmap='Blues', yticklabels=len(observed_emotions))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         angry  neutral\n",
            "angry      419      417\n",
            "neutral    402      362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOAcyKcQSR9t"
      },
      "source": [
        "f = []\n",
        "fn = []\n",
        "prob = []\n",
        "for file in glob.glob(\"C:\\\\Users\\\\acer-pc\\\\Desktop\\\\Audio\\\\Surrey Audio-Visual Expressed Emotion (SAVEE) Database\\\\AudioData\\\\JK\\\\*.wav\"):\n",
        "    file_name=os.path.basename(file)\n",
        "    feature=np.expand_dims(extract_feature(file, mfcc=True, chroma=True, mel=True, contrast=True, tonnetz=True).reshape(1, -1), axis=2)\n",
        "    int_pred = onehotencoder.inverse_transform(model2.predict(feature))[0][0]\n",
        "    pr = np.max(model2.predict(feature))\n",
        "    f.append(int_pred)\n",
        "    fn.append(file_name)\n",
        "    prob.append(pr)\n",
        "    \n",
        "df = pd.concat([pd.Series(fn), pd.Series(f), pd.Series(prob)], axis=1)\n",
        "df.columns = ['filename', 'emotion', 'prob']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Kpi-7RTDSR9y"
      },
      "source": [
        "df.to_csv('c.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIM5CJ4VSR91"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO7-JOHwSR92"
      },
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model_CNN.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(x_testcnn, y_test1, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc6O3OFySR96"
      },
      "source": [
        "file = (\"C:\\\\Users\\\\acer-pc\\\\Downloads\\\\LDC2007S09_neutral.wav\")\n",
        "file_name=os.path.basename(file)\n",
        "feature=np.expand_dims(extract_feature(file, mfcc=True, chroma=True, mel=True, contrast=True, tonnetz=True).reshape(1, -1), axis=2)\n",
        "int_pred = model2.predict(feature)\n",
        "int_preds = pd.DataFrame(int_pred)\n",
        "int_preds.columns = observed_emotions\n",
        "int_preds.idxmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEXu-T4kSR99"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}