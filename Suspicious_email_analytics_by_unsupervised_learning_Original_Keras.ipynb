{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Suspicious email analytics by unsupervised learning Original Keras.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bradbradlin/Machine-Learning-Projects/blob/main/Suspicious_email_analytics_by_unsupervised_learning_Original_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwpiX6xmqZG6"
      },
      "source": [
        "# Suspicious email detection by unsupervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg4R1nrWqZG-"
      },
      "source": [
        "Background:\n",
        "\n",
        "In the financial industry, email monitoring is one of measures to prevent from non compliance activities, for example rogue trading. Traditional monitoring of emails is screening by keywords which is manually maintained. Disadvantages of traditional approach include expensive human involvement and ineffectiveness. To oveecome those disadvantages, machine learning is a better alternative.  \n",
        "\n",
        "Nowadays, anomaly email detection, such as spam email, mainly adopts supervised algorithms. The pain point of supervised learning is labeled dataset which needs expensive human annotation.  To cope with this issue, this workbook will demonstrate an unsupervised learning technique to predict the probability of suspicious emails. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbpYav7MqZHA"
      },
      "source": [
        "### Supervised vs Unsupervised Learning:\n",
        "Unlike supervised learning, unsupervised learning don't need labeled dataset to train the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYJDf99qsrn3"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1Fu4MRSRGNZZaBw_9p-dcFJslhUHzUWUQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqH0HLI8cGu-"
      },
      "source": [
        "### The design of unsupervised learning for suspicious email detection:\n",
        "\n",
        "The training process is divided into 3 parts: Data Preparation, Feature Engineering and Model Training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-J_Hjkocjfb"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1tnTiN8ZeMMhxiGwlTMEJOq6za6sWdUPM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUkevh1KqZHE"
      },
      "source": [
        "### 1) Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bZaLytqZHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b463095-c5fd-4bd9-ed58-501fb86dc7ff"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import email\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.feature_extraction import stop_words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from scipy.spatial.distance import cosine\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tfl\n",
        "device_name = tfl.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEJRF3ItYCyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4202622d-9b76-4a98-b938-842a27751538"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwuK0zLlvWUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6500287-b2f9-48c9-c1f6-b8d41546d0d2"
      },
      "source": [
        "!pip install pydrive                             \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from pydrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (1.27.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (4.2.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (54.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBuPUNGfvYeM"
      },
      "source": [
        "from google.colab import auth                   \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgeagIEKvhcc"
      },
      "source": [
        "auth.authenticate_user()                        \n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNAxBzP1T9Qg"
      },
      "source": [
        "link = 'https://drive.google.com/open?id=1YDmzV3dp8pxDCbypvIRqbL2sTwa6bagU' # The shareable link\n",
        "fluff, id = link.split('=')\n",
        "#print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('emails.csv')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkGcIZCqZHT"
      },
      "source": [
        "The enron email dataset is used. It can be downloaded from https://www.kaggle.com/wcukierski/enron-email-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCMjXMPRYs09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f688c0-27b8-48b1-90d6-df10aca10eba"
      },
      "source": [
        "emails = pd.read_csv('emails.csv',quoting=2,header=0)\n",
        "emails = emails[emails['file'].str.contains('sent').tolist()]\n",
        "filelist = emails['file'].tolist()\n",
        "messages = emails['message'].tolist()\n",
        "print(messages[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
            "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: tim.belden@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen (Non-Privileged).pst\n",
            "\n",
            "Here is our forecast\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx9j1BKkT9DJ"
      },
      "source": [
        "def format_message(text):\n",
        "    sTemp=text\n",
        "    location=sTemp.find(\"---------------------- Forwarded\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\"----- Forwarded\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\"          ++++++CONFIDENTIALITY NOTICE+++++\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\"-----Original Message-----\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\" -----Original Appointment-----\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\"\\n\\t\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "    location=sTemp.find(\"@\")\n",
        "    if location!=-1:\n",
        "        sTemp=sTemp[:location]\n",
        "        sTemp=sTemp[:sTemp.rfind('\\n')]\n",
        "    return sTemp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7azzwdKTwSp"
      },
      "source": [
        "#Only 10 email adrresses are investigated\n",
        "filter_list = ['kay.mann@enron.com']\n",
        "min_words=10\n",
        "from_list = []\n",
        "subject_list = []\n",
        "message_list = []\n",
        "formatted_list = []\n",
        "\n",
        "#Import content into Dataframe\n",
        "for message in messages:\n",
        "    msg = email.message_from_string(message)\n",
        "    for part in msg.walk():\n",
        "        if part.get_content_type() == 'text/plain':\n",
        "            from_value = part.get(\"From\")\n",
        "            if from_value in filter_list:\n",
        "                sTemp = format_message(part.get_payload())\n",
        "                sTemp=sTemp.strip()\n",
        "                if len(sTemp) > 0:\n",
        "                    totalWords=0\n",
        "                    sentences=sent_tokenize(sTemp.lower())\n",
        "                    for sentence in sentences:\n",
        "                        words=word_tokenize(sentence)\n",
        "                        totalWords+=len(words)\n",
        "                    if totalWords>=min_words:\n",
        "                        from_list.append(part.get(\"From\"))\n",
        "                        subject_list.append(part.get(\"Subject\"))\n",
        "                        message_list.append(part.get_payload())\n",
        "                        formatted_list.append(sTemp)\n",
        "                    \n",
        "email_df = pd.DataFrame({'From': from_list, 'Subject': subject_list, 'Message': message_list, 'FormattedMessage': formatted_list,})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZ_1B7AqZHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835bfb81-9d7e-4cb8-a7c9-e4c951b78aa0"
      },
      "source": [
        "print('Size of total dataset: ', email_df.shape[0])\n",
        "email_df['Body'] = email_df['FormattedMessage']\n",
        "email_df_copy = email_df['Body'].copy() #Backup the orginal dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of total dataset:  6355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmHMskIZaUrS"
      },
      "source": [
        "#Loading anomaly samples\n",
        "link = 'https://drive.google.com/open?id=1EzMPaq1OaGr8tD7sQjB2fRF-KiFwRfzU' # The shareable link\n",
        "fluff, id = link.split('=')\n",
        "#print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('anomaly.csv')\n",
        "anomaly_df = pd.read_csv('anomaly.csv', encoding= 'iso-8859-1' , header=0, index_col=False)\n",
        "anomaly_df_copy = anomaly_df['Body'].copy() #Backup the orginal dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_g3p1xrd3Jh"
      },
      "source": [
        "def preprocess1(email_body): \n",
        "  email_body = email_body.astype('str') \n",
        "  email_body = email_body.str.strip() \n",
        "  email_body = email_body.apply(lambda x: \" \".join(x for x in x.split())) \n",
        "  email_body = email_body.str.strip()\n",
        "  #Removing /r/n \n",
        "  email_body = email_body.str.replace('\\nl\\r',' ')\n",
        "  # Clean missing field \n",
        "  email_body.fillna('NAN', inplace=True) \n",
        "  email_body = email_body.str.replace('?','') \n",
        "  return email_body "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49G86Jn4fYU-"
      },
      "source": [
        "def find_url(email_body): \n",
        "  urls = [] \n",
        "  for line in email_body:\n",
        "    #urls . re.findallChttps?://(?:[-Aw.]1(?:%[\\da-fA-F]-(21))+', line) \n",
        "    #urls2 = re.findallchttp[s]?://(?:[a-zA-Z]1[0-9] I ES-A•8,÷11[!*\\(1),]1 (?:%[(3 -9a-fA-F][0-9a -fA-F]))+1, line) \n",
        "    #urls3 = re.findall('Ahttp', line) \n",
        "    for word in line.split(): \n",
        "      #print(word) \n",
        "      if (word.strip().startswith(\"//\")) or (word.strip().startswith(\"http\")) or (word.strip().startswith(\"<http\")) or (word.strip().startswith(\"Mttp\")) or (word.strip().startswith(\"www\")) or (word.strip().startswith(\"<file:\")): \n",
        "        urls.append(word.lower()) \n",
        "        #print(word) \n",
        "  return urls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sY7zby1gWl3"
      },
      "source": [
        "def find_email_add(email_body): \n",
        "  email_df_add = [] \n",
        "  for line in email_body: \n",
        "    #email_df_add = re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\", line) \n",
        "    for word in line.split(): \n",
        "      if (word.strip().endswith(\".com\")) or (word.strip().endswith(\".com]\")) or (word.strip().endswith(\".com.hk\")) : \n",
        "        email_df_add.append(word.lower()) \n",
        "        #print(email_df_add) \n",
        "        #email_df_add = pd.DataFrame(email_df_add) \n",
        "  return email_df_add "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPX7y3mUydqD"
      },
      "source": [
        "def preprocess2(email_body): \n",
        "  # Pre-processing: \n",
        "  urls = find_url(email_body) \n",
        "  email_df_add = find_email_add(email_body) \n",
        "  # 1) Transform into lower case \n",
        "  email_body = email_body.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "  \n",
        "  # 2) Removing URL and email_df address \n",
        "  email_body = email_body.apply(lambda x: \" \". join(x for x in x.split() if x not in urls)) \n",
        "  email_body = email_body.apply(lambda x: \" \". join(x for x in x.split() if x not in email_df_add))\n",
        "\n",
        "  # 3) Removing Punctuation \n",
        "  email_body = email_body.str.replace('[^\\w\\s]',' ')\n",
        "  email_body = email_body.str.replace('[_]',' ')\n",
        "\n",
        "  # 4) Removing common words in email_df \n",
        "  #freq = pd.Series(' '.join(email_body).split()).value_counts()[:20] \n",
        "  #print(freq) \n",
        "  #email_body = email_body.apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "  \n",
        "  # 5) Removing rare words in email_df \n",
        "  #freq1 = pd.Series(' '.join(email_body).split()).value_counts()[-20:] \n",
        "  #print(freq1) \n",
        "  #email_body = email_body.apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
        "  \n",
        "  #6) Removing numeric character \n",
        "  email_body = email_body.str.replace('[0-9]+','')\n",
        "\n",
        "  #7) Stemming  \n",
        "  # stemmer = SnowballStemmer('english') \n",
        "  # email_body = [' '.join([stemmer.stem(word) for word in text.split(' ')])] \n",
        "\n",
        "  # 8) Lemmatizations \n",
        "  # lemmer = WordNetLemmatizer() \n",
        "  # email_body=[' '.join([lemmer.lemmatize(word) for word in text.split(' ')]) for text in email_body]\n",
        "\n",
        "  # 9) Removing stop words \n",
        "  # get stop word list from sklearn \n",
        "  #stop = ['thanks','regards','dear','miki','bea','liang']\n",
        "  stop = stop_words.ENGLISH_STOP_WORDS \n",
        "  stop2 = [''] \n",
        "  stop = stop.union(stop, stop2) \n",
        "  email_body = email_body.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "  #9) Strip space \n",
        "  email_body = pd.Series(email_body) \n",
        "  email_body = email_body.str.strip() \n",
        "  email_body = email_body.apply(lambda x: \" \".join(x for x in x.split())) \n",
        "  email_body = email_body.str.strip() \n",
        "  #email_df[['From: (Name)','Subject','Body']].tail() \n",
        "  return email_body "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8_Vx30ve21p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "dc7199b5-3859-49e1-f955-c2e44023de55"
      },
      "source": [
        "# Data preprocess\n",
        "email_df['Body'] = preprocess1(email_df['Body']) \n",
        "email_df['Body'] = preprocess2(email_df['Body'])\n",
        "anomaly_df['Body'] = preprocess1(anomaly_df['Body'])\n",
        "anomaly_df['Body'] = preprocess2(anomaly_df['Body'])\n",
        "email_df['Body_Original'] = email_df_copy\n",
        "anomaly_df['Body_Original'] = anomaly_df_copy \n",
        "print(email_df.shape)\n",
        "print(anomaly_df.shape)\n",
        "email_df[['From','Body']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6355, 6)\n",
            "(9, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>From</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kay.mann@enron.com</td>\n",
              "      <td>cancellation charges theirs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kay.mann@enron.com</td>\n",
              "      <td>revised currently lays deal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kay.mann@enron.com</td>\n",
              "      <td>hi lee confirm retention old turbines ve got t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kay.mann@enron.com</td>\n",
              "      <td>help quick look changes kay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kay.mann@enron.com</td>\n",
              "      <td>maybe mark doesn t know lance s trip carlos sole</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 From                                               Body\n",
              "0  kay.mann@enron.com                        cancellation charges theirs\n",
              "1  kay.mann@enron.com                        revised currently lays deal\n",
              "2  kay.mann@enron.com  hi lee confirm retention old turbines ve got t...\n",
              "3  kay.mann@enron.com                        help quick look changes kay\n",
              "4  kay.mann@enron.com   maybe mark doesn t know lance s trip carlos sole"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5wKoAWMYK3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac18fc50-f3f4-458b-a1b3-bf72d75f5ec3"
      },
      "source": [
        "y = np.zeros(email_df.shape[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(email_df, y, test_size=0.2, random_state=42) \n",
        "#X_test = pd.DataFrame() \n",
        "print(X_train.shape) \n",
        "print(X_test.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 6)\n",
            "(1271, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogEF3o7Og5ba"
      },
      "source": [
        "### 2) Feature Engineering\n",
        "In this part, feature engineering is performed including Keyword extraction (TF-IDF) and Topic Modeling (LDA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3GXWRgvi5Gl"
      },
      "source": [
        "### 2.1 Keyword extraction (TF-IDF)\n",
        "\n",
        "TF-IDF is adopted as a technique of automatic keyword extraction from email content. TF-IDF is used as one of features for training anomaly model.\n",
        "\n",
        "The formula of TF-IDF is shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_WJC8urBPV"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1kTNnG9QzAmER8biq08aozO-uCZR60o7I)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwjmiG6d611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588aad66-5b58-47c4-973b-55134e263ffd"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True, \n",
        "                                   smooth_idf=True, \n",
        "                                   ngram_range=(1,3), \n",
        "                                   max_features=10000, \n",
        "                                   max_df=0.50, \n",
        "                                   stop_words='english')\n",
        " \n",
        "X_ori = tfidf_vectorizer.fit_transform(X_train['Body'])\n",
        "X_ori_test = tfidf_vectorizer.transform(X_test['Body'])  \n",
        "X_anomaly = tfidf_vectorizer.transform(anomaly_df['Body']) \n",
        "print(X_ori.shape) \n",
        "print(X_anomaly.shape)  \n",
        "total_df = pd.DataFrame() \n",
        "for i in range(len(X_train)-5): \n",
        "  # place tf-idf values in a pandas data frame \n",
        "  df = pd.DataFrame(X_ori[i].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"]) \n",
        "  #print(i)\n",
        "  #print(df.sort_values(by=rtfidfuLascending=False).head(10)) \n",
        "  total_df = pd.concat([total_df, df.sort_values(by=['tfidf'],ascending=False).head(10)]) \n",
        "#Top tf-idf for all emails \n",
        "top_df = total_df.groupby(by=total_df.index).mean().sort_values(by=['tfidf'],ascending=False).head(20) \n",
        "top_df.reset_index(level=0, inplace=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 10000)\n",
            "(9, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7sZpzUoZKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb260ca-6e43-442a-e0da-a4880a9bdc09"
      },
      "source": [
        "my_model = PCA(n_components=200) \n",
        "X_PCA = my_model.fit_transform(X_ori.toarray()) # PCA \n",
        "X_PCA_test = my_model.transform(X_ori_test.toarray())\n",
        "my_model.explained_variance_ratio_.cumsum() \n",
        "scaler = StandardScaler() \n",
        "X_PCA = scaler.fit_transform(X_PCA) #Standardization \n",
        "X_PCA_test = scaler.transform(X_PCA_test) #Standardization \n",
        "print(X_PCA.shape)\n",
        "print(X_PCA_test.shape) \n",
        "X_anomaly_PCA = my_model.transform(X_anomaly.toarray()) # PCA \n",
        "my_model.explained_variance_ratio_.cumsum() \n",
        "X_anomaly_PCA = scaler.transform(X_anomaly_PCA) #Standardization \n",
        "print(X_anomaly_PCA.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 200)\n",
            "(1271, 200)\n",
            "(9, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPCxS8PnwFYx"
      },
      "source": [
        "### 2.2) Topic modeling (LDA)\n",
        "\n",
        " Latent Dirichlet Allocation (LDA) is one kind of topic model and is used to classify text in a document to a particular topic. In this example, the output of LDA is used as a feature for training anomaly model.\n",
        "\n",
        "# **\"Each document can be described by a distribution of topics and each topic can be described by a distribution of words\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3NUzTQ6yQ6K"
      },
      "source": [
        "![0_NFROMunwHvkRsi3K.jfif](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrUhxmDzpb4V"
      },
      "source": [
        "def display_topics(model, feature_names, no_top_words): \n",
        "  for topic_idx, topic in enumerate(model.components_): \n",
        "    print (\"Topic %d:\" % (topic_idx)) \n",
        "    print (\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHI_y3RoqnIf"
      },
      "source": [
        "no_features = 2000\n",
        "\n",
        "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model \n",
        "tf_vectorizer = CountVectorizer(max_df=0.8, max_features=no_features, stop_words='english', ngram_range=(1,1)) \n",
        "tf = tf_vectorizer.fit_transform(X_train['Body'])\n",
        "tf_test = tf_vectorizer.transform(X_test['Body'])\n",
        "tf_anomaly = tf_vectorizer.transform(anomaly_df['Body']) \n",
        "tf_feature_names = tf_vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBRWbnSAqq6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddcf52d-b04d-42b6-9e19-de335177cb30"
      },
      "source": [
        "no_topics = 30 \n",
        "no_iter = 200 \n",
        "# Run LDA \n",
        "lda = LatentDirichletAllocation(n_components=no_topics, \n",
        "                                max_iter=no_iter, \n",
        "                                learning_method='online', \n",
        "                                learning_offset=50., \n",
        "                                random_state=0).fit(tf) \n",
        "\n",
        "no_top_words = 10 \n",
        "display_topics(lda, tf_feature_names, no_top_words) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "kay check hi city just look ll thought don need\n",
            "Topic 1:\n",
            "kay thanks tomorrow meeting conference friday discuss ben available afternoon\n",
            "Topic 2:\n",
            "plant said energy environmental duke st power money use state\n",
            "Topic 3:\n",
            "kay interested just arrange ll thought monday scheduled available anytime\n",
            "Topic 4:\n",
            "agreement ena party shall purchase payment assignment enron agent equipment\n",
            "Topic 5:\n",
            "kay thanks number fax send need print copy john letter\n",
            "Topic 6:\n",
            "deal help speak area handled boyd lm directly perc expertise\n",
            "Topic 7:\n",
            "fuel power cell company energy gas cells fuelcell percent market\n",
            "Topic 8:\n",
            "good fyi sounds like kay didn maybe checked check discussed\n",
            "Topic 9:\n",
            "kay ge thanks agreement contract need version draft hi letter\n",
            "Topic 10:\n",
            "ena enron eecc legal counsel power outside review working involved\n",
            "Topic 11:\n",
            "right person far job enovate make looking ve figured chicago\n",
            "Topic 12:\n",
            "new year called early run york said game end based\n",
            "Topic 13:\n",
            "pm ca gregg going kay penman account big opps aren\n",
            "Topic 14:\n",
            "got pretty sound rest paige small generate dollar pay excited\n",
            "Topic 15:\n",
            "haven kay heard draft seen sheet david word ve stuff\n",
            "Topic 16:\n",
            "enron latest yes news corp trading wednesday update minutes jones\n",
            "Topic 17:\n",
            "michael ckm home hope carlos love neil great day paige\n",
            "Topic 18:\n",
            "gray change believe ben order needs barbara problems thanks really\n",
            "Topic 19:\n",
            "looking think work hot great day extent external extra face\n",
            "Topic 20:\n",
            "add th ones supposed action finance page ok finished default\n",
            "Topic 21:\n",
            "time did mike joe set asked miller experience paying hire\n",
            "Topic 22:\n",
            "site numbers reference email dates price delivery names units date\n",
            "Topic 23:\n",
            "shall seller performance buyer unit force event majeure notice energy\n",
            "Topic 24:\n",
            "kay know don think just week want today ll good\n",
            "Topic 25:\n",
            "didn kay talk way draft sound send transaction hope suggestions\n",
            "Topic 26:\n",
            "kay thanks hi ll email just looks know let like\n",
            "Topic 27:\n",
            "thank remember lawyers gave plus form hello paid note cool\n",
            "Topic 28:\n",
            "sent blackberry net wireless handheld www central received asking waiting\n",
            "Topic 29:\n",
            "turbopark transaction westlb wasn project llc sale ed changes kay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKtGK_L70pZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296651f8-08cb-4aaf-98ff-b34d7b4bb2e3"
      },
      "source": [
        "topic_df = lda.transform(tf)\n",
        "topic_df_test = lda.transform(tf_test)\n",
        "topic_df_anomaly = lda.transform(tf_anomaly) \n",
        "print(topic_df.shape)\n",
        "print(topic_df_test.shape)\n",
        "print(topic_df_anomaly.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 30)\n",
            "(1271, 30)\n",
            "(9, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ev-2ycULcP3"
      },
      "source": [
        "### 3) Anomaly detection by Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVx09MNZLmuF"
      },
      "source": [
        "Autoencoder is used for unsupervised anomaly detection. By learning to replicate the features in the training data, the model is encouraged to learn how to precisely reproduce the features. When facing anomalies, the model should worsen its reconstruction performance. By comparing input features and replicated output features, discrepancies can be used as an indicator of anomalies.\n",
        "\n",
        "The architecture of autoencoder is shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc0xBTg8Ppft"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1mhbleDHwhNNMtKugG53VUFywWukKEHVm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xF31onq41dr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9e04c5-1d9a-4cb7-d69f-949e5321b5e8"
      },
      "source": [
        "X1_dense = X_PCA \n",
        "X2_dense = np.concatenate((X1_dense, topic_df),axis=1) \n",
        "X1_dense_test = X_PCA_test \n",
        "X2_dense_test = np.concatenate((X1_dense_test, topic_df_test),axis=1) \n",
        "num_of_encoder = X2_dense.shape[1] \n",
        "num_of_hidden = int(X2_dense.shape[1]/2) \n",
        "print(X2_dense.shape) \n",
        "\n",
        "# input placeholder\n",
        "input_img = tfl.keras.layers.Input(shape=(num_of_encoder,))\n",
        "\n",
        "# this is the encoded representation of the input\n",
        "encoded = tfl.keras.layers.Dense(num_of_hidden*1.5, activation='relu', \n",
        "                                 kernel_initializer=tfl.keras.initializers.he_normal(seed=None))(input_img)\n",
        "\n",
        "# this is the encoded representation of the input\n",
        "encoded1 = tfl.keras.layers.Dense(num_of_hidden, activation='relu')(encoded)\n",
        "\n",
        "# this is the encoded representation of the input\n",
        "encoded2 = tfl.keras.layers.Dense(num_of_hidden*1.5, activation='relu')(encoded1)\n",
        "\n",
        "# this is the loss reconstruction of the input\n",
        "decoded = tfl.keras.layers.Dense(num_of_encoder, activation='tanh')(encoded2)\n",
        "\n",
        "# this model maps an input to its recommendation\n",
        "autoencoder = tfl.keras.models.Model(input_img, decoded)\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 230)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 230)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 172)               39732     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 115)               19895     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 172)               19952     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 230)               39790     \n",
            "=================================================================\n",
            "Total params: 119,369\n",
            "Trainable params: 119,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxUxeMc-5oJD"
      },
      "source": [
        "opt = tfl.keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9)\n",
        "autoencoder.compile(optimizer=opt, loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y5WG_Uj5xun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5d0869-5e85-4aaf-9154-3064fcb34877"
      },
      "source": [
        "# simple early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "# fit model\n",
        "autoencoder.fit(X2_dense, X2_dense, epochs=10000, batch_size=1028, shuffle=True, \n",
        "                validation_data=(X2_dense, X2_dense))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7501/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3688 - val_loss: 0.3697\n",
            "Epoch 7502/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3717\n",
            "Epoch 7503/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3747 - val_loss: 0.3706\n",
            "Epoch 7504/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3723\n",
            "Epoch 7505/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3715\n",
            "Epoch 7506/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3697\n",
            "Epoch 7507/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3730\n",
            "Epoch 7508/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3740\n",
            "Epoch 7509/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3770 - val_loss: 0.3687\n",
            "Epoch 7510/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3711 - val_loss: 0.3718\n",
            "Epoch 7511/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3739 - val_loss: 0.3701\n",
            "Epoch 7512/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3704 - val_loss: 0.3706\n",
            "Epoch 7513/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3725\n",
            "Epoch 7514/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3718\n",
            "Epoch 7515/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3710\n",
            "Epoch 7516/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3711\n",
            "Epoch 7517/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3708\n",
            "Epoch 7518/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3712\n",
            "Epoch 7519/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3697\n",
            "Epoch 7520/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3725\n",
            "Epoch 7521/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - val_loss: 0.3694\n",
            "Epoch 7522/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3712 - val_loss: 0.3693\n",
            "Epoch 7523/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3707\n",
            "Epoch 7524/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3743\n",
            "Epoch 7525/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3696\n",
            "Epoch 7526/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3713\n",
            "Epoch 7527/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3747 - val_loss: 0.3719\n",
            "Epoch 7528/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3714\n",
            "Epoch 7529/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3715\n",
            "Epoch 7530/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3732 - val_loss: 0.3711\n",
            "Epoch 7531/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3757 - val_loss: 0.3718\n",
            "Epoch 7532/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3739 - val_loss: 0.3672\n",
            "Epoch 7533/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3667 - val_loss: 0.3701\n",
            "Epoch 7534/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3733 - val_loss: 0.3735\n",
            "Epoch 7535/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3747 - val_loss: 0.3703\n",
            "Epoch 7536/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3706\n",
            "Epoch 7537/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3709\n",
            "Epoch 7538/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3728\n",
            "Epoch 7539/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3722\n",
            "Epoch 7540/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3723\n",
            "Epoch 7541/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3745 - val_loss: 0.3703\n",
            "Epoch 7542/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3706\n",
            "Epoch 7543/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3719\n",
            "Epoch 7544/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3713\n",
            "Epoch 7545/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3711 - val_loss: 0.3766\n",
            "Epoch 7546/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3703\n",
            "Epoch 7547/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3752 - val_loss: 0.3714\n",
            "Epoch 7548/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3701\n",
            "Epoch 7549/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3687\n",
            "Epoch 7550/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3725 - val_loss: 0.3713\n",
            "Epoch 7551/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3715\n",
            "Epoch 7552/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3719\n",
            "Epoch 7553/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3709\n",
            "Epoch 7554/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3727\n",
            "Epoch 7555/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3702\n",
            "Epoch 7556/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3705\n",
            "Epoch 7557/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3692\n",
            "Epoch 7558/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3714\n",
            "Epoch 7559/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3745 - val_loss: 0.3721\n",
            "Epoch 7560/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3704\n",
            "Epoch 7561/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3748 - val_loss: 0.3704\n",
            "Epoch 7562/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3700\n",
            "Epoch 7563/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3707 - val_loss: 0.3698\n",
            "Epoch 7564/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3725\n",
            "Epoch 7565/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3749 - val_loss: 0.3695\n",
            "Epoch 7566/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3711\n",
            "Epoch 7567/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3712\n",
            "Epoch 7568/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3699\n",
            "Epoch 7569/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3713\n",
            "Epoch 7570/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3712\n",
            "Epoch 7571/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3746 - val_loss: 0.3686\n",
            "Epoch 7572/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3688 - val_loss: 0.3741\n",
            "Epoch 7573/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3729\n",
            "Epoch 7574/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3699\n",
            "Epoch 7575/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3692\n",
            "Epoch 7576/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3711\n",
            "Epoch 7577/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3740\n",
            "Epoch 7578/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3714\n",
            "Epoch 7579/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3707\n",
            "Epoch 7580/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3707\n",
            "Epoch 7581/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3725\n",
            "Epoch 7582/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3696\n",
            "Epoch 7583/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3756\n",
            "Epoch 7584/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3765 - val_loss: 0.3712\n",
            "Epoch 7585/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3736 - val_loss: 0.3725\n",
            "Epoch 7586/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3722\n",
            "Epoch 7587/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3706\n",
            "Epoch 7588/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3691 - val_loss: 0.3702\n",
            "Epoch 7589/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3720 - val_loss: 0.3719\n",
            "Epoch 7590/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3700\n",
            "Epoch 7591/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3688\n",
            "Epoch 7592/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3728\n",
            "Epoch 7593/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3734\n",
            "Epoch 7594/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3749 - val_loss: 0.3720\n",
            "Epoch 7595/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3721\n",
            "Epoch 7596/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3732 - val_loss: 0.3692\n",
            "Epoch 7597/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3734\n",
            "Epoch 7598/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3711\n",
            "Epoch 7599/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3710\n",
            "Epoch 7600/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3723\n",
            "Epoch 7601/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3719\n",
            "Epoch 7602/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3706\n",
            "Epoch 7603/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3722\n",
            "Epoch 7604/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3703\n",
            "Epoch 7605/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3742\n",
            "Epoch 7606/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3739 - val_loss: 0.3736\n",
            "Epoch 7607/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3710\n",
            "Epoch 7608/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3721\n",
            "Epoch 7609/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3697\n",
            "Epoch 7610/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3713\n",
            "Epoch 7611/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3723\n",
            "Epoch 7612/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3741 - val_loss: 0.3714\n",
            "Epoch 7613/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3732 - val_loss: 0.3697\n",
            "Epoch 7614/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3719\n",
            "Epoch 7615/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3750 - val_loss: 0.3707\n",
            "Epoch 7616/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3702\n",
            "Epoch 7617/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3698\n",
            "Epoch 7618/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3743 - val_loss: 0.3698\n",
            "Epoch 7619/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3710\n",
            "Epoch 7620/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3725\n",
            "Epoch 7621/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3693\n",
            "Epoch 7622/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3735\n",
            "Epoch 7623/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3710\n",
            "Epoch 7624/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.3707\n",
            "Epoch 7625/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3732\n",
            "Epoch 7626/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3715\n",
            "Epoch 7627/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3712\n",
            "Epoch 7628/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3692\n",
            "Epoch 7629/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3732\n",
            "Epoch 7630/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3736 - val_loss: 0.3744\n",
            "Epoch 7631/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3778 - val_loss: 0.3695\n",
            "Epoch 7632/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3727\n",
            "Epoch 7633/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3697\n",
            "Epoch 7634/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3728\n",
            "Epoch 7635/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3740 - val_loss: 0.3718\n",
            "Epoch 7636/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3706\n",
            "Epoch 7637/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3719\n",
            "Epoch 7638/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3725\n",
            "Epoch 7639/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3720\n",
            "Epoch 7640/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3689\n",
            "Epoch 7641/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3715\n",
            "Epoch 7642/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3751\n",
            "Epoch 7643/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3745 - val_loss: 0.3718\n",
            "Epoch 7644/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3718\n",
            "Epoch 7645/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3757 - val_loss: 0.3705\n",
            "Epoch 7646/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3723\n",
            "Epoch 7647/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3721\n",
            "Epoch 7648/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3722 - val_loss: 0.3707\n",
            "Epoch 7649/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3673 - val_loss: 0.3738\n",
            "Epoch 7650/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3741 - val_loss: 0.3691\n",
            "Epoch 7651/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3737\n",
            "Epoch 7652/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3749 - val_loss: 0.3704\n",
            "Epoch 7653/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3700 - val_loss: 0.3695\n",
            "Epoch 7654/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3721\n",
            "Epoch 7655/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3770 - val_loss: 0.3706\n",
            "Epoch 7656/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3706\n",
            "Epoch 7657/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3737 - val_loss: 0.3696\n",
            "Epoch 7658/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3725\n",
            "Epoch 7659/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3709\n",
            "Epoch 7660/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3719\n",
            "Epoch 7661/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3737\n",
            "Epoch 7662/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3760 - val_loss: 0.3718\n",
            "Epoch 7663/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3723\n",
            "Epoch 7664/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3703\n",
            "Epoch 7665/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3724\n",
            "Epoch 7666/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3726\n",
            "Epoch 7667/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3760 - val_loss: 0.3701\n",
            "Epoch 7668/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3712\n",
            "Epoch 7669/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3680 - val_loss: 0.3730\n",
            "Epoch 7670/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3745 - val_loss: 0.3694\n",
            "Epoch 7671/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3711\n",
            "Epoch 7672/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3721\n",
            "Epoch 7673/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3719\n",
            "Epoch 7674/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3711\n",
            "Epoch 7675/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3698\n",
            "Epoch 7676/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3713 - val_loss: 0.3731\n",
            "Epoch 7677/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3742 - val_loss: 0.3695\n",
            "Epoch 7678/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3711\n",
            "Epoch 7679/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3713\n",
            "Epoch 7680/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3712\n",
            "Epoch 7681/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3702\n",
            "Epoch 7682/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3750 - val_loss: 0.3747\n",
            "Epoch 7683/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3702\n",
            "Epoch 7684/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3713 - val_loss: 0.3722\n",
            "Epoch 7685/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3697\n",
            "Epoch 7686/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3730\n",
            "Epoch 7687/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3726\n",
            "Epoch 7688/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3729\n",
            "Epoch 7689/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3762 - val_loss: 0.3695\n",
            "Epoch 7690/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3712\n",
            "Epoch 7691/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3741\n",
            "Epoch 7692/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3752 - val_loss: 0.3708\n",
            "Epoch 7693/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3700\n",
            "Epoch 7694/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3700\n",
            "Epoch 7695/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3736\n",
            "Epoch 7696/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3724 - val_loss: 0.3707\n",
            "Epoch 7697/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3708\n",
            "Epoch 7698/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3729\n",
            "Epoch 7699/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3754 - val_loss: 0.3706\n",
            "Epoch 7700/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3688\n",
            "Epoch 7701/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3737\n",
            "Epoch 7702/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3694\n",
            "Epoch 7703/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3719\n",
            "Epoch 7704/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3745 - val_loss: 0.3720\n",
            "Epoch 7705/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3756 - val_loss: 0.3722\n",
            "Epoch 7706/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3709\n",
            "Epoch 7707/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3718\n",
            "Epoch 7708/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3728\n",
            "Epoch 7709/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3724\n",
            "Epoch 7710/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3751 - val_loss: 0.3714\n",
            "Epoch 7711/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3701\n",
            "Epoch 7712/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3718\n",
            "Epoch 7713/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3702\n",
            "Epoch 7714/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3705\n",
            "Epoch 7715/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3705\n",
            "Epoch 7716/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3724\n",
            "Epoch 7717/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3720\n",
            "Epoch 7718/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3699\n",
            "Epoch 7719/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3686\n",
            "Epoch 7720/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3740\n",
            "Epoch 7721/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3740 - val_loss: 0.3733\n",
            "Epoch 7722/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3712\n",
            "Epoch 7723/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3716\n",
            "Epoch 7724/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3694\n",
            "Epoch 7725/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3711\n",
            "Epoch 7726/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3711\n",
            "Epoch 7727/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3741\n",
            "Epoch 7728/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3717\n",
            "Epoch 7729/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3715\n",
            "Epoch 7730/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3691\n",
            "Epoch 7731/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3726\n",
            "Epoch 7732/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3714 - val_loss: 0.3716\n",
            "Epoch 7733/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 7734/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 7735/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3731 - val_loss: 0.3699\n",
            "Epoch 7736/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3703\n",
            "Epoch 7737/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3693\n",
            "Epoch 7738/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3711\n",
            "Epoch 7739/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3711\n",
            "Epoch 7740/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3750 - val_loss: 0.3695\n",
            "Epoch 7741/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3702\n",
            "Epoch 7742/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3720 - val_loss: 0.3730\n",
            "Epoch 7743/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3729\n",
            "Epoch 7744/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3685\n",
            "Epoch 7745/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3734\n",
            "Epoch 7746/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3734 - val_loss: 0.3741\n",
            "Epoch 7747/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3693\n",
            "Epoch 7748/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.3716\n",
            "Epoch 7749/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3702\n",
            "Epoch 7750/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3703\n",
            "Epoch 7751/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3702\n",
            "Epoch 7752/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3694\n",
            "Epoch 7753/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3706\n",
            "Epoch 7754/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3714\n",
            "Epoch 7755/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3741 - val_loss: 0.3690\n",
            "Epoch 7756/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3704\n",
            "Epoch 7757/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3741\n",
            "Epoch 7758/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3702\n",
            "Epoch 7759/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3729\n",
            "Epoch 7760/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3704\n",
            "Epoch 7761/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3726\n",
            "Epoch 7762/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3683\n",
            "Epoch 7763/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3724\n",
            "Epoch 7764/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3737\n",
            "Epoch 7765/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3730\n",
            "Epoch 7766/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3689\n",
            "Epoch 7767/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3726\n",
            "Epoch 7768/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3718\n",
            "Epoch 7769/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3726 - val_loss: 0.3726\n",
            "Epoch 7770/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3702\n",
            "Epoch 7771/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3735\n",
            "Epoch 7772/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3764 - val_loss: 0.3705\n",
            "Epoch 7773/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3721\n",
            "Epoch 7774/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3694\n",
            "Epoch 7775/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3703\n",
            "Epoch 7776/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3734\n",
            "Epoch 7777/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3709\n",
            "Epoch 7778/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3717 - val_loss: 0.3718\n",
            "Epoch 7779/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3712\n",
            "Epoch 7780/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3704\n",
            "Epoch 7781/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3705\n",
            "Epoch 7782/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3714\n",
            "Epoch 7783/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3728\n",
            "Epoch 7784/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3729\n",
            "Epoch 7785/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3731\n",
            "Epoch 7786/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3699\n",
            "Epoch 7787/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3726\n",
            "Epoch 7788/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3718\n",
            "Epoch 7789/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3713\n",
            "Epoch 7790/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3732 - val_loss: 0.3717\n",
            "Epoch 7791/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3719\n",
            "Epoch 7792/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3704\n",
            "Epoch 7793/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3722\n",
            "Epoch 7794/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3731 - val_loss: 0.3728\n",
            "Epoch 7795/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3771 - val_loss: 0.3695\n",
            "Epoch 7796/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3693\n",
            "Epoch 7797/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3700\n",
            "Epoch 7798/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3715\n",
            "Epoch 7799/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3730\n",
            "Epoch 7800/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3712\n",
            "Epoch 7801/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3721\n",
            "Epoch 7802/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3743 - val_loss: 0.3713\n",
            "Epoch 7803/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3717 - val_loss: 0.3733\n",
            "Epoch 7804/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3725\n",
            "Epoch 7805/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3723\n",
            "Epoch 7806/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3754 - val_loss: 0.3716\n",
            "Epoch 7807/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3714\n",
            "Epoch 7808/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3688\n",
            "Epoch 7809/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3688 - val_loss: 0.3719\n",
            "Epoch 7810/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3742\n",
            "Epoch 7811/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3747 - val_loss: 0.3723\n",
            "Epoch 7812/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3706\n",
            "Epoch 7813/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3716\n",
            "Epoch 7814/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3732\n",
            "Epoch 7815/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3717\n",
            "Epoch 7816/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3710\n",
            "Epoch 7817/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3736\n",
            "Epoch 7818/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3737 - val_loss: 0.3704\n",
            "Epoch 7819/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3697\n",
            "Epoch 7820/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3721\n",
            "Epoch 7821/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3723\n",
            "Epoch 7822/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3715\n",
            "Epoch 7823/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3718\n",
            "Epoch 7824/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3703\n",
            "Epoch 7825/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3707\n",
            "Epoch 7826/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3723\n",
            "Epoch 7827/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3759 - val_loss: 0.3698\n",
            "Epoch 7828/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3716\n",
            "Epoch 7829/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3721\n",
            "Epoch 7830/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3708\n",
            "Epoch 7831/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3695\n",
            "Epoch 7832/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3733\n",
            "Epoch 7833/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3761 - val_loss: 0.3710\n",
            "Epoch 7834/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3720\n",
            "Epoch 7835/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3711\n",
            "Epoch 7836/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3718 - val_loss: 0.3674\n",
            "Epoch 7837/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3714\n",
            "Epoch 7838/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3696\n",
            "Epoch 7839/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3736\n",
            "Epoch 7840/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3723\n",
            "Epoch 7841/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3739 - val_loss: 0.3712\n",
            "Epoch 7842/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3699\n",
            "Epoch 7843/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3701\n",
            "Epoch 7844/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3745\n",
            "Epoch 7845/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3702\n",
            "Epoch 7846/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3738 - val_loss: 0.3711\n",
            "Epoch 7847/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3736\n",
            "Epoch 7848/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3697\n",
            "Epoch 7849/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3733\n",
            "Epoch 7850/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3763 - val_loss: 0.3702\n",
            "Epoch 7851/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3725\n",
            "Epoch 7852/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3724\n",
            "Epoch 7853/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3720\n",
            "Epoch 7854/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3721\n",
            "Epoch 7855/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3710\n",
            "Epoch 7856/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3707\n",
            "Epoch 7857/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3730\n",
            "Epoch 7858/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3719\n",
            "Epoch 7859/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3702\n",
            "Epoch 7860/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3707\n",
            "Epoch 7861/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3712\n",
            "Epoch 7862/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3740\n",
            "Epoch 7863/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3737 - val_loss: 0.3693\n",
            "Epoch 7864/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3709\n",
            "Epoch 7865/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3723\n",
            "Epoch 7866/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3707\n",
            "Epoch 7867/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3684 - val_loss: 0.3702\n",
            "Epoch 7868/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3729\n",
            "Epoch 7869/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3745 - val_loss: 0.3712\n",
            "Epoch 7870/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3730 - val_loss: 0.3696\n",
            "Epoch 7871/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3710\n",
            "Epoch 7872/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3721\n",
            "Epoch 7873/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3706\n",
            "Epoch 7874/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3704 - val_loss: 0.3728\n",
            "Epoch 7875/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3701\n",
            "Epoch 7876/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3684\n",
            "Epoch 7877/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3731\n",
            "Epoch 7878/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3699\n",
            "Epoch 7879/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3718\n",
            "Epoch 7880/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3706 - val_loss: 0.3745\n",
            "Epoch 7881/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3716\n",
            "Epoch 7882/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3715\n",
            "Epoch 7883/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3685\n",
            "Epoch 7884/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3715\n",
            "Epoch 7885/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3713\n",
            "Epoch 7886/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3698\n",
            "Epoch 7887/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3711\n",
            "Epoch 7888/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3713\n",
            "Epoch 7889/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3685\n",
            "Epoch 7890/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3691\n",
            "Epoch 7891/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3701 - val_loss: 0.3704\n",
            "Epoch 7892/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3725\n",
            "Epoch 7893/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3720\n",
            "Epoch 7894/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3713\n",
            "Epoch 7895/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3699\n",
            "Epoch 7896/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3739\n",
            "Epoch 7897/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3723\n",
            "Epoch 7898/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3709\n",
            "Epoch 7899/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3745\n",
            "Epoch 7900/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3695\n",
            "Epoch 7901/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3711\n",
            "Epoch 7902/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3734\n",
            "Epoch 7903/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3698\n",
            "Epoch 7904/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3703\n",
            "Epoch 7905/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3710\n",
            "Epoch 7906/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3705\n",
            "Epoch 7907/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3718\n",
            "Epoch 7908/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3724\n",
            "Epoch 7909/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3696\n",
            "Epoch 7910/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3705\n",
            "Epoch 7911/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3716 - val_loss: 0.3725\n",
            "Epoch 7912/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3706\n",
            "Epoch 7913/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3699\n",
            "Epoch 7914/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3726\n",
            "Epoch 7915/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3703\n",
            "Epoch 7916/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3718\n",
            "Epoch 7917/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3727\n",
            "Epoch 7918/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3714\n",
            "Epoch 7919/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3716\n",
            "Epoch 7920/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3711\n",
            "Epoch 7921/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3686\n",
            "Epoch 7922/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3719\n",
            "Epoch 7923/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3733 - val_loss: 0.3704\n",
            "Epoch 7924/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3720\n",
            "Epoch 7925/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3754 - val_loss: 0.3713\n",
            "Epoch 7926/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3750 - val_loss: 0.3709\n",
            "Epoch 7927/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3706\n",
            "Epoch 7928/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3718\n",
            "Epoch 7929/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3707 - val_loss: 0.3715\n",
            "Epoch 7930/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3736 - val_loss: 0.3719\n",
            "Epoch 7931/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3709\n",
            "Epoch 7932/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3727\n",
            "Epoch 7933/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3683\n",
            "Epoch 7934/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3715\n",
            "Epoch 7935/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3716\n",
            "Epoch 7936/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3738\n",
            "Epoch 7937/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3705\n",
            "Epoch 7938/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3700\n",
            "Epoch 7939/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3725\n",
            "Epoch 7940/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3695\n",
            "Epoch 7941/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3711\n",
            "Epoch 7942/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3713 - val_loss: 0.3723\n",
            "Epoch 7943/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3712\n",
            "Epoch 7944/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3726\n",
            "Epoch 7945/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3680\n",
            "Epoch 7946/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3697\n",
            "Epoch 7947/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3733\n",
            "Epoch 7948/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3751 - val_loss: 0.3705\n",
            "Epoch 7949/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3684\n",
            "Epoch 7950/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3702\n",
            "Epoch 7951/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3710\n",
            "Epoch 7952/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3700\n",
            "Epoch 7953/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3685\n",
            "Epoch 7954/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3740\n",
            "Epoch 7955/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3742 - val_loss: 0.3699\n",
            "Epoch 7956/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3713\n",
            "Epoch 7957/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3745 - val_loss: 0.3715\n",
            "Epoch 7958/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3709\n",
            "Epoch 7959/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3707\n",
            "Epoch 7960/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3695\n",
            "Epoch 7961/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3714\n",
            "Epoch 7962/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3719\n",
            "Epoch 7963/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3685\n",
            "Epoch 7964/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3732\n",
            "Epoch 7965/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3722\n",
            "Epoch 7966/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3701\n",
            "Epoch 7967/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3723\n",
            "Epoch 7968/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3712\n",
            "Epoch 7969/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3759 - val_loss: 0.3700\n",
            "Epoch 7970/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3703\n",
            "Epoch 7971/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3708\n",
            "Epoch 7972/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3705\n",
            "Epoch 7973/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3719\n",
            "Epoch 7974/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3699\n",
            "Epoch 7975/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3712\n",
            "Epoch 7976/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3705\n",
            "Epoch 7977/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3714\n",
            "Epoch 7978/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3729 - val_loss: 0.3716\n",
            "Epoch 7979/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3715 - val_loss: 0.3709\n",
            "Epoch 7980/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3726\n",
            "Epoch 7981/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3699\n",
            "Epoch 7982/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3743\n",
            "Epoch 7983/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3722\n",
            "Epoch 7984/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3717\n",
            "Epoch 7985/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3707\n",
            "Epoch 7986/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3706\n",
            "Epoch 7987/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3752\n",
            "Epoch 7988/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3711\n",
            "Epoch 7989/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3698\n",
            "Epoch 7990/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3732\n",
            "Epoch 7991/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - val_loss: 0.3712\n",
            "Epoch 7992/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3704\n",
            "Epoch 7993/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3734\n",
            "Epoch 7994/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3741 - val_loss: 0.3707\n",
            "Epoch 7995/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3739 - val_loss: 0.3711\n",
            "Epoch 7996/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3705\n",
            "Epoch 7997/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3722\n",
            "Epoch 7998/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3721\n",
            "Epoch 7999/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3752\n",
            "Epoch 8000/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3713\n",
            "Epoch 8001/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3727\n",
            "Epoch 8002/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3692\n",
            "Epoch 8003/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3729\n",
            "Epoch 8004/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3724 - val_loss: 0.3703\n",
            "Epoch 8005/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3728\n",
            "Epoch 8006/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3694\n",
            "Epoch 8007/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3697\n",
            "Epoch 8008/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3746\n",
            "Epoch 8009/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3681\n",
            "Epoch 8010/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3700\n",
            "Epoch 8011/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3722\n",
            "Epoch 8012/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3714\n",
            "Epoch 8013/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3707\n",
            "Epoch 8014/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3722\n",
            "Epoch 8015/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3727\n",
            "Epoch 8016/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3698\n",
            "Epoch 8017/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3693\n",
            "Epoch 8018/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3737\n",
            "Epoch 8019/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3719\n",
            "Epoch 8020/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3718\n",
            "Epoch 8021/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.3719\n",
            "Epoch 8022/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3713\n",
            "Epoch 8023/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3695\n",
            "Epoch 8024/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3712\n",
            "Epoch 8025/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3735\n",
            "Epoch 8026/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3760 - val_loss: 0.3702\n",
            "Epoch 8027/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3730\n",
            "Epoch 8028/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3723\n",
            "Epoch 8029/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3731 - val_loss: 0.3690\n",
            "Epoch 8030/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3732 - val_loss: 0.3700\n",
            "Epoch 8031/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3709\n",
            "Epoch 8032/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3723 - val_loss: 0.3692\n",
            "Epoch 8033/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3720 - val_loss: 0.3733\n",
            "Epoch 8034/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3729 - val_loss: 0.3715\n",
            "Epoch 8035/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3727 - val_loss: 0.3737\n",
            "Epoch 8036/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3762 - val_loss: 0.3724\n",
            "Epoch 8037/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3734 - val_loss: 0.3707\n",
            "Epoch 8038/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3692\n",
            "Epoch 8039/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3735\n",
            "Epoch 8040/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3704 - val_loss: 0.3709\n",
            "Epoch 8041/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3730\n",
            "Epoch 8042/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3707\n",
            "Epoch 8043/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3707\n",
            "Epoch 8044/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3694\n",
            "Epoch 8045/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3749\n",
            "Epoch 8046/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3763 - val_loss: 0.3685\n",
            "Epoch 8047/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3708\n",
            "Epoch 8048/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3710\n",
            "Epoch 8049/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3741\n",
            "Epoch 8050/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3740 - val_loss: 0.3686\n",
            "Epoch 8051/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3725\n",
            "Epoch 8052/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3696\n",
            "Epoch 8053/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3726 - val_loss: 0.3729\n",
            "Epoch 8054/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3742\n",
            "Epoch 8055/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3752 - val_loss: 0.3693\n",
            "Epoch 8056/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3722\n",
            "Epoch 8057/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3692\n",
            "Epoch 8058/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3713\n",
            "Epoch 8059/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3723\n",
            "Epoch 8060/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3698\n",
            "Epoch 8061/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3707\n",
            "Epoch 8062/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3699\n",
            "Epoch 8063/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3725\n",
            "Epoch 8064/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3726\n",
            "Epoch 8065/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3721 - val_loss: 0.3702\n",
            "Epoch 8066/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3717\n",
            "Epoch 8067/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3698\n",
            "Epoch 8068/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3685\n",
            "Epoch 8069/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3747\n",
            "Epoch 8070/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3777 - val_loss: 0.3703\n",
            "Epoch 8071/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3712\n",
            "Epoch 8072/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3695\n",
            "Epoch 8073/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3687\n",
            "Epoch 8074/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3713\n",
            "Epoch 8075/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3738\n",
            "Epoch 8076/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3708\n",
            "Epoch 8077/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3726\n",
            "Epoch 8078/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 8079/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3710\n",
            "Epoch 8080/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3704\n",
            "Epoch 8081/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3724\n",
            "Epoch 8082/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3727\n",
            "Epoch 8083/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3711\n",
            "Epoch 8084/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3706\n",
            "Epoch 8085/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3709\n",
            "Epoch 8086/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3710\n",
            "Epoch 8087/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3728\n",
            "Epoch 8088/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3712\n",
            "Epoch 8089/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3721\n",
            "Epoch 8090/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3753 - val_loss: 0.3673\n",
            "Epoch 8091/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3701\n",
            "Epoch 8092/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3735\n",
            "Epoch 8093/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3733\n",
            "Epoch 8094/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3710\n",
            "Epoch 8095/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3736\n",
            "Epoch 8096/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3709\n",
            "Epoch 8097/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3701\n",
            "Epoch 8098/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3730\n",
            "Epoch 8099/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3723\n",
            "Epoch 8100/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3747 - val_loss: 0.3690\n",
            "Epoch 8101/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3750\n",
            "Epoch 8102/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3765 - val_loss: 0.3727\n",
            "Epoch 8103/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3757 - val_loss: 0.3706\n",
            "Epoch 8104/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3697\n",
            "Epoch 8105/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3723\n",
            "Epoch 8106/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - val_loss: 0.3713\n",
            "Epoch 8107/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3722\n",
            "Epoch 8108/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3713\n",
            "Epoch 8109/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3696\n",
            "Epoch 8110/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3748\n",
            "Epoch 8111/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3700\n",
            "Epoch 8112/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3718\n",
            "Epoch 8113/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3701\n",
            "Epoch 8114/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3708\n",
            "Epoch 8115/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3715 - val_loss: 0.3702\n",
            "Epoch 8116/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3714 - val_loss: 0.3722\n",
            "Epoch 8117/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3701\n",
            "Epoch 8118/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3739\n",
            "Epoch 8119/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3709\n",
            "Epoch 8120/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3729\n",
            "Epoch 8121/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3698\n",
            "Epoch 8122/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3696\n",
            "Epoch 8123/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3702\n",
            "Epoch 8124/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3727 - val_loss: 0.3715\n",
            "Epoch 8125/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3733\n",
            "Epoch 8126/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3768 - val_loss: 0.3710\n",
            "Epoch 8127/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3709 - val_loss: 0.3720\n",
            "Epoch 8128/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3692\n",
            "Epoch 8129/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3715\n",
            "Epoch 8130/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3701\n",
            "Epoch 8131/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3703\n",
            "Epoch 8132/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3721\n",
            "Epoch 8133/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3748 - val_loss: 0.3733\n",
            "Epoch 8134/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3702\n",
            "Epoch 8135/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3733 - val_loss: 0.3680\n",
            "Epoch 8136/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3700\n",
            "Epoch 8137/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3713\n",
            "Epoch 8138/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3731\n",
            "Epoch 8139/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3749 - val_loss: 0.3711\n",
            "Epoch 8140/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3706\n",
            "Epoch 8141/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3729\n",
            "Epoch 8142/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3747 - val_loss: 0.3699\n",
            "Epoch 8143/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3711\n",
            "Epoch 8144/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3733\n",
            "Epoch 8145/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3676\n",
            "Epoch 8146/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3726\n",
            "Epoch 8147/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3710\n",
            "Epoch 8148/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3701 - val_loss: 0.3726\n",
            "Epoch 8149/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3756 - val_loss: 0.3702\n",
            "Epoch 8150/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3703\n",
            "Epoch 8151/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3741 - val_loss: 0.3710\n",
            "Epoch 8152/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3710\n",
            "Epoch 8153/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3722\n",
            "Epoch 8154/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3745\n",
            "Epoch 8155/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3723\n",
            "Epoch 8156/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3718\n",
            "Epoch 8157/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3742\n",
            "Epoch 8158/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3737 - val_loss: 0.3710\n",
            "Epoch 8159/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3728\n",
            "Epoch 8160/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3716\n",
            "Epoch 8161/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3712\n",
            "Epoch 8162/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3739 - val_loss: 0.3716\n",
            "Epoch 8163/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3693\n",
            "Epoch 8164/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3692\n",
            "Epoch 8165/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3707\n",
            "Epoch 8166/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3748 - val_loss: 0.3724\n",
            "Epoch 8167/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3702\n",
            "Epoch 8168/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3698\n",
            "Epoch 8169/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3714\n",
            "Epoch 8170/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3701\n",
            "Epoch 8171/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3726\n",
            "Epoch 8172/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.3713\n",
            "Epoch 8173/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3720\n",
            "Epoch 8174/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3681\n",
            "Epoch 8175/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3704\n",
            "Epoch 8176/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3720 - val_loss: 0.3718\n",
            "Epoch 8177/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3702\n",
            "Epoch 8178/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3712\n",
            "Epoch 8179/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3733 - val_loss: 0.3724\n",
            "Epoch 8180/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3759\n",
            "Epoch 8181/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3761 - val_loss: 0.3688\n",
            "Epoch 8182/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3697\n",
            "Epoch 8183/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3709\n",
            "Epoch 8184/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3698\n",
            "Epoch 8185/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3715\n",
            "Epoch 8186/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3720\n",
            "Epoch 8187/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3712\n",
            "Epoch 8188/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3736\n",
            "Epoch 8189/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3740 - val_loss: 0.3712\n",
            "Epoch 8190/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3748 - val_loss: 0.3688\n",
            "Epoch 8191/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3729\n",
            "Epoch 8192/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3748 - val_loss: 0.3715\n",
            "Epoch 8193/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3755 - val_loss: 0.3690\n",
            "Epoch 8194/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 8195/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3717 - val_loss: 0.3720\n",
            "Epoch 8196/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3698\n",
            "Epoch 8197/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3698\n",
            "Epoch 8198/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3732\n",
            "Epoch 8199/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3714\n",
            "Epoch 8200/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3714\n",
            "Epoch 8201/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3738 - val_loss: 0.3686\n",
            "Epoch 8202/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3698\n",
            "Epoch 8203/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3702\n",
            "Epoch 8204/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3743\n",
            "Epoch 8205/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3756 - val_loss: 0.3722\n",
            "Epoch 8206/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3711\n",
            "Epoch 8207/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3732 - val_loss: 0.3705\n",
            "Epoch 8208/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3713\n",
            "Epoch 8209/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3696\n",
            "Epoch 8210/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3752\n",
            "Epoch 8211/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3723\n",
            "Epoch 8212/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3755 - val_loss: 0.3710\n",
            "Epoch 8213/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3698\n",
            "Epoch 8214/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3730\n",
            "Epoch 8215/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3690\n",
            "Epoch 8216/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3685 - val_loss: 0.3733\n",
            "Epoch 8217/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3728\n",
            "Epoch 8218/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3699 - val_loss: 0.3723\n",
            "Epoch 8219/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3723\n",
            "Epoch 8220/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3697\n",
            "Epoch 8221/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3731 - val_loss: 0.3698\n",
            "Epoch 8222/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3700\n",
            "Epoch 8223/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3691\n",
            "Epoch 8224/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3728\n",
            "Epoch 8225/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3710 - val_loss: 0.3730\n",
            "Epoch 8226/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3728\n",
            "Epoch 8227/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3705\n",
            "Epoch 8228/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3726\n",
            "Epoch 8229/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3708\n",
            "Epoch 8230/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3729\n",
            "Epoch 8231/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3727\n",
            "Epoch 8232/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3705\n",
            "Epoch 8233/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3696\n",
            "Epoch 8234/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3697\n",
            "Epoch 8235/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3723\n",
            "Epoch 8236/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3691 - val_loss: 0.3712\n",
            "Epoch 8237/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3696\n",
            "Epoch 8238/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3724\n",
            "Epoch 8239/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3714\n",
            "Epoch 8240/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3708\n",
            "Epoch 8241/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3733\n",
            "Epoch 8242/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3758 - val_loss: 0.3696\n",
            "Epoch 8243/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3720\n",
            "Epoch 8244/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3723\n",
            "Epoch 8245/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3710\n",
            "Epoch 8246/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3693\n",
            "Epoch 8247/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3716\n",
            "Epoch 8248/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3682\n",
            "Epoch 8249/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3732\n",
            "Epoch 8250/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3711\n",
            "Epoch 8251/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3734\n",
            "Epoch 8252/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3713\n",
            "Epoch 8253/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3710\n",
            "Epoch 8254/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3689\n",
            "Epoch 8255/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3693\n",
            "Epoch 8256/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3717\n",
            "Epoch 8257/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3736\n",
            "Epoch 8258/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3748\n",
            "Epoch 8259/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3756 - val_loss: 0.3714\n",
            "Epoch 8260/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3722\n",
            "Epoch 8261/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3673\n",
            "Epoch 8262/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3700 - val_loss: 0.3704\n",
            "Epoch 8263/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3743\n",
            "Epoch 8264/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3720\n",
            "Epoch 8265/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3692\n",
            "Epoch 8266/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3720\n",
            "Epoch 8267/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3699\n",
            "Epoch 8268/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3709\n",
            "Epoch 8269/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3691\n",
            "Epoch 8270/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3705\n",
            "Epoch 8271/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3721\n",
            "Epoch 8272/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3718\n",
            "Epoch 8273/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3697\n",
            "Epoch 8274/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3719\n",
            "Epoch 8275/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3675\n",
            "Epoch 8276/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3716\n",
            "Epoch 8277/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3716\n",
            "Epoch 8278/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3717 - val_loss: 0.3707\n",
            "Epoch 8279/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3747\n",
            "Epoch 8280/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3750 - val_loss: 0.3700\n",
            "Epoch 8281/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3700\n",
            "Epoch 8282/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3695\n",
            "Epoch 8283/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3726\n",
            "Epoch 8284/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3711\n",
            "Epoch 8285/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3707\n",
            "Epoch 8286/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3711\n",
            "Epoch 8287/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3707\n",
            "Epoch 8288/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3724\n",
            "Epoch 8289/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3690\n",
            "Epoch 8290/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3705\n",
            "Epoch 8291/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3751\n",
            "Epoch 8292/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3690\n",
            "Epoch 8293/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3718\n",
            "Epoch 8294/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3713 - val_loss: 0.3688\n",
            "Epoch 8295/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3688\n",
            "Epoch 8296/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3666 - val_loss: 0.3737\n",
            "Epoch 8297/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3727\n",
            "Epoch 8298/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3746 - val_loss: 0.3712\n",
            "Epoch 8299/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3718 - val_loss: 0.3714\n",
            "Epoch 8300/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3717\n",
            "Epoch 8301/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3718\n",
            "Epoch 8302/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3684\n",
            "Epoch 8303/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3699 - val_loss: 0.3718\n",
            "Epoch 8304/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3707\n",
            "Epoch 8305/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3741\n",
            "Epoch 8306/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3708\n",
            "Epoch 8307/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3711\n",
            "Epoch 8308/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3712\n",
            "Epoch 8309/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3752 - val_loss: 0.3720\n",
            "Epoch 8310/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3706\n",
            "Epoch 8311/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3737 - val_loss: 0.3718\n",
            "Epoch 8312/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3738\n",
            "Epoch 8313/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3714\n",
            "Epoch 8314/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3717\n",
            "Epoch 8315/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3702\n",
            "Epoch 8316/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3709 - val_loss: 0.3718\n",
            "Epoch 8317/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3717\n",
            "Epoch 8318/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3687\n",
            "Epoch 8319/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3677 - val_loss: 0.3703\n",
            "Epoch 8320/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3751 - val_loss: 0.3687\n",
            "Epoch 8321/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3736\n",
            "Epoch 8322/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3746 - val_loss: 0.3699\n",
            "Epoch 8323/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3722 - val_loss: 0.3712\n",
            "Epoch 8324/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3725\n",
            "Epoch 8325/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3697\n",
            "Epoch 8326/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3713\n",
            "Epoch 8327/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3696 - val_loss: 0.3685\n",
            "Epoch 8328/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3717\n",
            "Epoch 8329/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3719\n",
            "Epoch 8330/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3710\n",
            "Epoch 8331/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3705\n",
            "Epoch 8332/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3714\n",
            "Epoch 8333/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3726\n",
            "Epoch 8334/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3706\n",
            "Epoch 8335/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3711\n",
            "Epoch 8336/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3701\n",
            "Epoch 8337/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3719\n",
            "Epoch 8338/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3697\n",
            "Epoch 8339/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3685 - val_loss: 0.3708\n",
            "Epoch 8340/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3699\n",
            "Epoch 8341/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3694\n",
            "Epoch 8342/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3691\n",
            "Epoch 8343/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3705\n",
            "Epoch 8344/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3693\n",
            "Epoch 8345/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3719\n",
            "Epoch 8346/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3730\n",
            "Epoch 8347/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3745 - val_loss: 0.3704\n",
            "Epoch 8348/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3687\n",
            "Epoch 8349/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3723\n",
            "Epoch 8350/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3698\n",
            "Epoch 8351/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3699 - val_loss: 0.3724\n",
            "Epoch 8352/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3700\n",
            "Epoch 8353/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3716\n",
            "Epoch 8354/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3750 - val_loss: 0.3718\n",
            "Epoch 8355/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3738\n",
            "Epoch 8356/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3761 - val_loss: 0.3688\n",
            "Epoch 8357/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3688 - val_loss: 0.3734\n",
            "Epoch 8358/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3760 - val_loss: 0.3701\n",
            "Epoch 8359/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3710\n",
            "Epoch 8360/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3704 - val_loss: 0.3706\n",
            "Epoch 8361/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3694\n",
            "Epoch 8362/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3717\n",
            "Epoch 8363/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3715\n",
            "Epoch 8364/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3708\n",
            "Epoch 8365/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3740 - val_loss: 0.3712\n",
            "Epoch 8366/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3724\n",
            "Epoch 8367/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3710\n",
            "Epoch 8368/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3716\n",
            "Epoch 8369/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3705\n",
            "Epoch 8370/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3725\n",
            "Epoch 8371/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3728\n",
            "Epoch 8372/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3750 - val_loss: 0.3713\n",
            "Epoch 8373/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3696\n",
            "Epoch 8374/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3705\n",
            "Epoch 8375/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3737\n",
            "Epoch 8376/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3705\n",
            "Epoch 8377/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3698\n",
            "Epoch 8378/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3710\n",
            "Epoch 8379/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3726\n",
            "Epoch 8380/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3708\n",
            "Epoch 8381/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3702\n",
            "Epoch 8382/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3709\n",
            "Epoch 8383/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3731 - val_loss: 0.3705\n",
            "Epoch 8384/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3668\n",
            "Epoch 8385/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3683 - val_loss: 0.3738\n",
            "Epoch 8386/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3697\n",
            "Epoch 8387/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3693 - val_loss: 0.3712\n",
            "Epoch 8388/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3709\n",
            "Epoch 8389/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3708\n",
            "Epoch 8390/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3696\n",
            "Epoch 8391/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3684\n",
            "Epoch 8392/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3725\n",
            "Epoch 8393/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3761 - val_loss: 0.3683\n",
            "Epoch 8394/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3695\n",
            "Epoch 8395/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3700\n",
            "Epoch 8396/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3709\n",
            "Epoch 8397/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3720\n",
            "Epoch 8398/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3703\n",
            "Epoch 8399/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3699\n",
            "Epoch 8400/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3696\n",
            "Epoch 8401/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3715\n",
            "Epoch 8402/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3691\n",
            "Epoch 8403/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3718\n",
            "Epoch 8404/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3684\n",
            "Epoch 8405/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3708\n",
            "Epoch 8406/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3731 - val_loss: 0.3734\n",
            "Epoch 8407/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3706\n",
            "Epoch 8408/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3704\n",
            "Epoch 8409/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3701\n",
            "Epoch 8410/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3729 - val_loss: 0.3677\n",
            "Epoch 8411/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3690 - val_loss: 0.3704\n",
            "Epoch 8412/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3727 - val_loss: 0.3723\n",
            "Epoch 8413/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3717\n",
            "Epoch 8414/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3710\n",
            "Epoch 8415/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3715\n",
            "Epoch 8416/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3718\n",
            "Epoch 8417/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3706\n",
            "Epoch 8418/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3707\n",
            "Epoch 8419/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3703\n",
            "Epoch 8420/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3710\n",
            "Epoch 8421/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3733 - val_loss: 0.3699\n",
            "Epoch 8422/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3713 - val_loss: 0.3712\n",
            "Epoch 8423/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3690\n",
            "Epoch 8424/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3696 - val_loss: 0.3690\n",
            "Epoch 8425/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3680 - val_loss: 0.3733\n",
            "Epoch 8426/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3718 - val_loss: 0.3699\n",
            "Epoch 8427/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3733\n",
            "Epoch 8428/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3694\n",
            "Epoch 8429/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3701 - val_loss: 0.3697\n",
            "Epoch 8430/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3718 - val_loss: 0.3699\n",
            "Epoch 8431/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3713 - val_loss: 0.3725\n",
            "Epoch 8432/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3743 - val_loss: 0.3716\n",
            "Epoch 8433/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3709\n",
            "Epoch 8434/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3689\n",
            "Epoch 8435/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3730\n",
            "Epoch 8436/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.3671\n",
            "Epoch 8437/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3691 - val_loss: 0.3747\n",
            "Epoch 8438/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3747 - val_loss: 0.3702\n",
            "Epoch 8439/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3722\n",
            "Epoch 8440/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3713\n",
            "Epoch 8441/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3700\n",
            "Epoch 8442/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3698\n",
            "Epoch 8443/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3704\n",
            "Epoch 8444/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3691\n",
            "Epoch 8445/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3716\n",
            "Epoch 8446/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3737 - val_loss: 0.3706\n",
            "Epoch 8447/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3710\n",
            "Epoch 8448/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3704\n",
            "Epoch 8449/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3708\n",
            "Epoch 8450/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3706\n",
            "Epoch 8451/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3735 - val_loss: 0.3731\n",
            "Epoch 8452/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3703\n",
            "Epoch 8453/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3727 - val_loss: 0.3708\n",
            "Epoch 8454/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3731\n",
            "Epoch 8455/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3691\n",
            "Epoch 8456/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3694 - val_loss: 0.3721\n",
            "Epoch 8457/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3708 - val_loss: 0.3704\n",
            "Epoch 8458/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3738\n",
            "Epoch 8459/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3711\n",
            "Epoch 8460/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3696\n",
            "Epoch 8461/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3684\n",
            "Epoch 8462/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3696 - val_loss: 0.3711\n",
            "Epoch 8463/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3712\n",
            "Epoch 8464/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3725\n",
            "Epoch 8465/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3710\n",
            "Epoch 8466/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3715\n",
            "Epoch 8467/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3700\n",
            "Epoch 8468/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3706\n",
            "Epoch 8469/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3719 - val_loss: 0.3714\n",
            "Epoch 8470/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3712\n",
            "Epoch 8471/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3699 - val_loss: 0.3712\n",
            "Epoch 8472/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3729 - val_loss: 0.3695\n",
            "Epoch 8473/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3698 - val_loss: 0.3716\n",
            "Epoch 8474/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3677\n",
            "Epoch 8475/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3722\n",
            "Epoch 8476/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3704\n",
            "Epoch 8477/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3698 - val_loss: 0.3688\n",
            "Epoch 8478/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3720\n",
            "Epoch 8479/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3743\n",
            "Epoch 8480/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3692\n",
            "Epoch 8481/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3710\n",
            "Epoch 8482/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.3684\n",
            "Epoch 8483/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3692\n",
            "Epoch 8484/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3710\n",
            "Epoch 8485/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3736\n",
            "Epoch 8486/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - val_loss: 0.3716\n",
            "Epoch 8487/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3695\n",
            "Epoch 8488/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3685\n",
            "Epoch 8489/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3731\n",
            "Epoch 8490/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3704\n",
            "Epoch 8491/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3704 - val_loss: 0.3689\n",
            "Epoch 8492/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3699\n",
            "Epoch 8493/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3718\n",
            "Epoch 8494/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3687\n",
            "Epoch 8495/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3697\n",
            "Epoch 8496/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3712\n",
            "Epoch 8497/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3697\n",
            "Epoch 8498/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3699\n",
            "Epoch 8499/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3704\n",
            "Epoch 8500/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3703\n",
            "Epoch 8501/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3712\n",
            "Epoch 8502/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3704\n",
            "Epoch 8503/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3693\n",
            "Epoch 8504/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3694\n",
            "Epoch 8505/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 8506/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3686 - val_loss: 0.3734\n",
            "Epoch 8507/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.3688\n",
            "Epoch 8508/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3697\n",
            "Epoch 8509/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3676\n",
            "Epoch 8510/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3715\n",
            "Epoch 8511/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3713\n",
            "Epoch 8512/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3723\n",
            "Epoch 8513/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3681\n",
            "Epoch 8514/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3699\n",
            "Epoch 8515/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3759\n",
            "Epoch 8516/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3754 - val_loss: 0.3696\n",
            "Epoch 8517/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3717\n",
            "Epoch 8518/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3730\n",
            "Epoch 8519/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3699\n",
            "Epoch 8520/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3693\n",
            "Epoch 8521/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3725\n",
            "Epoch 8522/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3704 - val_loss: 0.3712\n",
            "Epoch 8523/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3704\n",
            "Epoch 8524/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3734\n",
            "Epoch 8525/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3693\n",
            "Epoch 8526/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3712\n",
            "Epoch 8527/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3705\n",
            "Epoch 8528/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3702\n",
            "Epoch 8529/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3717 - val_loss: 0.3702\n",
            "Epoch 8530/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3718 - val_loss: 0.3707\n",
            "Epoch 8531/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3689\n",
            "Epoch 8532/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3687\n",
            "Epoch 8533/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3683 - val_loss: 0.3719\n",
            "Epoch 8534/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3763 - val_loss: 0.3685\n",
            "Epoch 8535/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3701\n",
            "Epoch 8536/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3683\n",
            "Epoch 8537/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3689\n",
            "Epoch 8538/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3720\n",
            "Epoch 8539/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3725\n",
            "Epoch 8540/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3713\n",
            "Epoch 8541/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3687\n",
            "Epoch 8542/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3682 - val_loss: 0.3726\n",
            "Epoch 8543/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3720 - val_loss: 0.3733\n",
            "Epoch 8544/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3682\n",
            "Epoch 8545/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3748\n",
            "Epoch 8546/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3762 - val_loss: 0.3699\n",
            "Epoch 8547/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3689\n",
            "Epoch 8548/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3693\n",
            "Epoch 8549/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3706\n",
            "Epoch 8550/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3693\n",
            "Epoch 8551/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3692 - val_loss: 0.3699\n",
            "Epoch 8552/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3713\n",
            "Epoch 8553/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3704\n",
            "Epoch 8554/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3679\n",
            "Epoch 8555/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3712 - val_loss: 0.3721\n",
            "Epoch 8556/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3685\n",
            "Epoch 8557/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3724\n",
            "Epoch 8558/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3701\n",
            "Epoch 8559/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3703\n",
            "Epoch 8560/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3718\n",
            "Epoch 8561/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3697\n",
            "Epoch 8562/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3692\n",
            "Epoch 8563/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3703\n",
            "Epoch 8564/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3696\n",
            "Epoch 8565/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3687\n",
            "Epoch 8566/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3702\n",
            "Epoch 8567/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3705 - val_loss: 0.3717\n",
            "Epoch 8568/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3740 - val_loss: 0.3697\n",
            "Epoch 8569/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3704\n",
            "Epoch 8570/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 8571/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3678\n",
            "Epoch 8572/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3724\n",
            "Epoch 8573/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3704\n",
            "Epoch 8574/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - val_loss: 0.3693\n",
            "Epoch 8575/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3715\n",
            "Epoch 8576/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3685\n",
            "Epoch 8577/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3708\n",
            "Epoch 8578/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3702\n",
            "Epoch 8579/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3698\n",
            "Epoch 8580/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3685\n",
            "Epoch 8581/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3682 - val_loss: 0.3742\n",
            "Epoch 8582/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3732 - val_loss: 0.3712\n",
            "Epoch 8583/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3685\n",
            "Epoch 8584/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3689\n",
            "Epoch 8585/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3727\n",
            "Epoch 8586/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3745 - val_loss: 0.3686\n",
            "Epoch 8587/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3706\n",
            "Epoch 8588/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3692\n",
            "Epoch 8589/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3698\n",
            "Epoch 8590/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3707 - val_loss: 0.3710\n",
            "Epoch 8591/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3714\n",
            "Epoch 8592/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3679\n",
            "Epoch 8593/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3700\n",
            "Epoch 8594/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3724\n",
            "Epoch 8595/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3712\n",
            "Epoch 8596/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3697\n",
            "Epoch 8597/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3709\n",
            "Epoch 8598/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3706\n",
            "Epoch 8599/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3709\n",
            "Epoch 8600/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3698\n",
            "Epoch 8601/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3705\n",
            "Epoch 8602/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3718 - val_loss: 0.3714\n",
            "Epoch 8603/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3702\n",
            "Epoch 8604/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3705 - val_loss: 0.3709\n",
            "Epoch 8605/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3692\n",
            "Epoch 8606/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3679\n",
            "Epoch 8607/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3713\n",
            "Epoch 8608/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3700\n",
            "Epoch 8609/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3715\n",
            "Epoch 8610/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3703\n",
            "Epoch 8611/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3701\n",
            "Epoch 8612/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3726\n",
            "Epoch 8613/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3716\n",
            "Epoch 8614/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3699\n",
            "Epoch 8615/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3727 - val_loss: 0.3724\n",
            "Epoch 8616/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3719\n",
            "Epoch 8617/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3679\n",
            "Epoch 8618/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3743\n",
            "Epoch 8619/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3699\n",
            "Epoch 8620/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3728\n",
            "Epoch 8621/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3695\n",
            "Epoch 8622/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3707\n",
            "Epoch 8623/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3728\n",
            "Epoch 8624/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3692\n",
            "Epoch 8625/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3741 - val_loss: 0.3701\n",
            "Epoch 8626/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3716\n",
            "Epoch 8627/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3720 - val_loss: 0.3698\n",
            "Epoch 8628/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3694\n",
            "Epoch 8629/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3716 - val_loss: 0.3713\n",
            "Epoch 8630/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3722 - val_loss: 0.3689\n",
            "Epoch 8631/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3690 - val_loss: 0.3704\n",
            "Epoch 8632/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3707\n",
            "Epoch 8633/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3698\n",
            "Epoch 8634/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3721\n",
            "Epoch 8635/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3713\n",
            "Epoch 8636/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3705\n",
            "Epoch 8637/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3712\n",
            "Epoch 8638/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3695\n",
            "Epoch 8639/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3738\n",
            "Epoch 8640/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3729 - val_loss: 0.3697\n",
            "Epoch 8641/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3710\n",
            "Epoch 8642/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3706\n",
            "Epoch 8643/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3684\n",
            "Epoch 8644/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3720\n",
            "Epoch 8645/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3706\n",
            "Epoch 8646/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3718 - val_loss: 0.3725\n",
            "Epoch 8647/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3705 - val_loss: 0.3705\n",
            "Epoch 8648/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3713\n",
            "Epoch 8649/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3692\n",
            "Epoch 8650/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3744\n",
            "Epoch 8651/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3751 - val_loss: 0.3714\n",
            "Epoch 8652/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3704\n",
            "Epoch 8653/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3732\n",
            "Epoch 8654/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3745 - val_loss: 0.3681\n",
            "Epoch 8655/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3724\n",
            "Epoch 8656/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3747 - val_loss: 0.3710\n",
            "Epoch 8657/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3727\n",
            "Epoch 8658/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3702\n",
            "Epoch 8659/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3703\n",
            "Epoch 8660/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3704\n",
            "Epoch 8661/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3728\n",
            "Epoch 8662/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3742 - val_loss: 0.3711\n",
            "Epoch 8663/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3698\n",
            "Epoch 8664/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3727 - val_loss: 0.3726\n",
            "Epoch 8665/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3696\n",
            "Epoch 8666/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3719 - val_loss: 0.3702\n",
            "Epoch 8667/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3740 - val_loss: 0.3691\n",
            "Epoch 8668/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3689\n",
            "Epoch 8669/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3695\n",
            "Epoch 8670/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3729\n",
            "Epoch 8671/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3689\n",
            "Epoch 8672/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3713\n",
            "Epoch 8673/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3684\n",
            "Epoch 8674/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3700\n",
            "Epoch 8675/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3702\n",
            "Epoch 8676/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3718\n",
            "Epoch 8677/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3700\n",
            "Epoch 8678/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3698\n",
            "Epoch 8679/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3710\n",
            "Epoch 8680/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3695\n",
            "Epoch 8681/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3709\n",
            "Epoch 8682/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3730 - val_loss: 0.3702\n",
            "Epoch 8683/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3738 - val_loss: 0.3717\n",
            "Epoch 8684/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3693\n",
            "Epoch 8685/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3706\n",
            "Epoch 8686/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3708\n",
            "Epoch 8687/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3693\n",
            "Epoch 8688/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3704\n",
            "Epoch 8689/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3692\n",
            "Epoch 8690/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3728\n",
            "Epoch 8691/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3701\n",
            "Epoch 8692/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3705\n",
            "Epoch 8693/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3695\n",
            "Epoch 8694/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3722\n",
            "Epoch 8695/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3707\n",
            "Epoch 8696/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3700\n",
            "Epoch 8697/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3702\n",
            "Epoch 8698/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3708\n",
            "Epoch 8699/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3711\n",
            "Epoch 8700/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3716\n",
            "Epoch 8701/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3705\n",
            "Epoch 8702/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3704 - val_loss: 0.3709\n",
            "Epoch 8703/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3719 - val_loss: 0.3697\n",
            "Epoch 8704/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3700\n",
            "Epoch 8705/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3702\n",
            "Epoch 8706/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3726\n",
            "Epoch 8707/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3687\n",
            "Epoch 8708/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3716\n",
            "Epoch 8709/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3716 - val_loss: 0.3709\n",
            "Epoch 8710/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3716\n",
            "Epoch 8711/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3692\n",
            "Epoch 8712/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3708\n",
            "Epoch 8713/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3720\n",
            "Epoch 8714/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3702\n",
            "Epoch 8715/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3695\n",
            "Epoch 8716/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3724\n",
            "Epoch 8717/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3670\n",
            "Epoch 8718/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3722\n",
            "Epoch 8719/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3750 - val_loss: 0.3686\n",
            "Epoch 8720/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3681 - val_loss: 0.3740\n",
            "Epoch 8721/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3690\n",
            "Epoch 8722/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3714\n",
            "Epoch 8723/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3691\n",
            "Epoch 8724/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3703\n",
            "Epoch 8725/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3692\n",
            "Epoch 8726/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3734\n",
            "Epoch 8727/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3720\n",
            "Epoch 8728/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3713\n",
            "Epoch 8729/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3702\n",
            "Epoch 8730/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3708\n",
            "Epoch 8731/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3712\n",
            "Epoch 8732/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3687\n",
            "Epoch 8733/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3718\n",
            "Epoch 8734/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3706\n",
            "Epoch 8735/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3693\n",
            "Epoch 8736/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3699\n",
            "Epoch 8737/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3710\n",
            "Epoch 8738/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3678\n",
            "Epoch 8739/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3684 - val_loss: 0.3702\n",
            "Epoch 8740/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3745 - val_loss: 0.3713\n",
            "Epoch 8741/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3707\n",
            "Epoch 8742/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3704\n",
            "Epoch 8743/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3692\n",
            "Epoch 8744/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3694\n",
            "Epoch 8745/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3705\n",
            "Epoch 8746/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3683\n",
            "Epoch 8747/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3719\n",
            "Epoch 8748/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3700\n",
            "Epoch 8749/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3721\n",
            "Epoch 8750/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3743 - val_loss: 0.3691\n",
            "Epoch 8751/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3684\n",
            "Epoch 8752/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3708\n",
            "Epoch 8753/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3717 - val_loss: 0.3692\n",
            "Epoch 8754/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3690 - val_loss: 0.3686\n",
            "Epoch 8755/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3700\n",
            "Epoch 8756/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3706\n",
            "Epoch 8757/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3698\n",
            "Epoch 8758/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3682\n",
            "Epoch 8759/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3713\n",
            "Epoch 8760/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3688\n",
            "Epoch 8761/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3675\n",
            "Epoch 8762/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3697\n",
            "Epoch 8763/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3703\n",
            "Epoch 8764/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3727 - val_loss: 0.3696\n",
            "Epoch 8765/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3695\n",
            "Epoch 8766/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3684\n",
            "Epoch 8767/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3686\n",
            "Epoch 8768/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3675 - val_loss: 0.3728\n",
            "Epoch 8769/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3715\n",
            "Epoch 8770/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3679\n",
            "Epoch 8771/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3694 - val_loss: 0.3697\n",
            "Epoch 8772/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3679 - val_loss: 0.3684\n",
            "Epoch 8773/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3712\n",
            "Epoch 8774/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3750 - val_loss: 0.3694\n",
            "Epoch 8775/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3714\n",
            "Epoch 8776/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3678\n",
            "Epoch 8777/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3689\n",
            "Epoch 8778/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3719\n",
            "Epoch 8779/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3713\n",
            "Epoch 8780/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3706\n",
            "Epoch 8781/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3674\n",
            "Epoch 8782/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3679\n",
            "Epoch 8783/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3704\n",
            "Epoch 8784/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3705\n",
            "Epoch 8785/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3693\n",
            "Epoch 8786/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3698\n",
            "Epoch 8787/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3699\n",
            "Epoch 8788/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3689\n",
            "Epoch 8789/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3704\n",
            "Epoch 8790/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3700\n",
            "Epoch 8791/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3735\n",
            "Epoch 8792/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3762 - val_loss: 0.3708\n",
            "Epoch 8793/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3683\n",
            "Epoch 8794/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3705\n",
            "Epoch 8795/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3707\n",
            "Epoch 8796/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3693\n",
            "Epoch 8797/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3683\n",
            "Epoch 8798/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3693\n",
            "Epoch 8799/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3727\n",
            "Epoch 8800/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3720\n",
            "Epoch 8801/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3689\n",
            "Epoch 8802/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3718\n",
            "Epoch 8803/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3699\n",
            "Epoch 8804/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3699\n",
            "Epoch 8805/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3729\n",
            "Epoch 8806/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3670\n",
            "Epoch 8807/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - val_loss: 0.3697\n",
            "Epoch 8808/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3750\n",
            "Epoch 8809/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3715\n",
            "Epoch 8810/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3738 - val_loss: 0.3697\n",
            "Epoch 8811/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3713\n",
            "Epoch 8812/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3685\n",
            "Epoch 8813/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3707 - val_loss: 0.3717\n",
            "Epoch 8814/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3737 - val_loss: 0.3693\n",
            "Epoch 8815/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3721 - val_loss: 0.3704\n",
            "Epoch 8816/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3754\n",
            "Epoch 8817/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3754 - val_loss: 0.3674\n",
            "Epoch 8818/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3689\n",
            "Epoch 8819/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3721\n",
            "Epoch 8820/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3699\n",
            "Epoch 8821/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3698\n",
            "Epoch 8822/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3708\n",
            "Epoch 8823/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3685\n",
            "Epoch 8824/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3700\n",
            "Epoch 8825/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3710\n",
            "Epoch 8826/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3720\n",
            "Epoch 8827/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3676\n",
            "Epoch 8828/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3692\n",
            "Epoch 8829/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3712\n",
            "Epoch 8830/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3721\n",
            "Epoch 8831/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3694\n",
            "Epoch 8832/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3692\n",
            "Epoch 8833/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3710\n",
            "Epoch 8834/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3689\n",
            "Epoch 8835/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3714\n",
            "Epoch 8836/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3706\n",
            "Epoch 8837/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3689\n",
            "Epoch 8838/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3684\n",
            "Epoch 8839/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3708\n",
            "Epoch 8840/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3713 - val_loss: 0.3706\n",
            "Epoch 8841/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3694\n",
            "Epoch 8842/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3717\n",
            "Epoch 8843/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3711\n",
            "Epoch 8844/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3688\n",
            "Epoch 8845/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3715\n",
            "Epoch 8846/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3708\n",
            "Epoch 8847/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3722\n",
            "Epoch 8848/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3703\n",
            "Epoch 8849/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3682 - val_loss: 0.3701\n",
            "Epoch 8850/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3705\n",
            "Epoch 8851/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3705\n",
            "Epoch 8852/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3686\n",
            "Epoch 8853/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3697\n",
            "Epoch 8854/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3698\n",
            "Epoch 8855/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3691\n",
            "Epoch 8856/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3715\n",
            "Epoch 8857/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3704\n",
            "Epoch 8858/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3683\n",
            "Epoch 8859/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3675 - val_loss: 0.3717\n",
            "Epoch 8860/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3710\n",
            "Epoch 8861/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3720\n",
            "Epoch 8862/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3687\n",
            "Epoch 8863/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3704\n",
            "Epoch 8864/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3717\n",
            "Epoch 8865/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3711\n",
            "Epoch 8866/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3704\n",
            "Epoch 8867/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3727\n",
            "Epoch 8868/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.3712\n",
            "Epoch 8869/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3706\n",
            "Epoch 8870/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3689\n",
            "Epoch 8871/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3698\n",
            "Epoch 8872/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3704\n",
            "Epoch 8873/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3708\n",
            "Epoch 8874/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3707\n",
            "Epoch 8875/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3701\n",
            "Epoch 8876/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3686\n",
            "Epoch 8877/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3700\n",
            "Epoch 8878/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3678\n",
            "Epoch 8879/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3728\n",
            "Epoch 8880/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3694\n",
            "Epoch 8881/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3720\n",
            "Epoch 8882/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3727 - val_loss: 0.3694\n",
            "Epoch 8883/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3685\n",
            "Epoch 8884/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3709\n",
            "Epoch 8885/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3716\n",
            "Epoch 8886/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3683\n",
            "Epoch 8887/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3693\n",
            "Epoch 8888/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3688 - val_loss: 0.3690\n",
            "Epoch 8889/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3713\n",
            "Epoch 8890/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3721\n",
            "Epoch 8891/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3745 - val_loss: 0.3705\n",
            "Epoch 8892/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3682\n",
            "Epoch 8893/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3702\n",
            "Epoch 8894/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3683\n",
            "Epoch 8895/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3700\n",
            "Epoch 8896/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3717\n",
            "Epoch 8897/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3684\n",
            "Epoch 8898/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3701 - val_loss: 0.3695\n",
            "Epoch 8899/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3689\n",
            "Epoch 8900/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3680\n",
            "Epoch 8901/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3703\n",
            "Epoch 8902/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3700\n",
            "Epoch 8903/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3717\n",
            "Epoch 8904/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3714\n",
            "Epoch 8905/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3685\n",
            "Epoch 8906/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3699\n",
            "Epoch 8907/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3706\n",
            "Epoch 8908/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3696\n",
            "Epoch 8909/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3693\n",
            "Epoch 8910/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3684\n",
            "Epoch 8911/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3702\n",
            "Epoch 8912/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3704\n",
            "Epoch 8913/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3703 - val_loss: 0.3687\n",
            "Epoch 8914/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3713\n",
            "Epoch 8915/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3684\n",
            "Epoch 8916/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3726\n",
            "Epoch 8917/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3764 - val_loss: 0.3712\n",
            "Epoch 8918/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3678\n",
            "Epoch 8919/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3685\n",
            "Epoch 8920/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3677\n",
            "Epoch 8921/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3672\n",
            "Epoch 8922/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3732\n",
            "Epoch 8923/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3711\n",
            "Epoch 8924/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3716\n",
            "Epoch 8925/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3746 - val_loss: 0.3709\n",
            "Epoch 8926/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3688\n",
            "Epoch 8927/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3684 - val_loss: 0.3693\n",
            "Epoch 8928/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3699\n",
            "Epoch 8929/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3699\n",
            "Epoch 8930/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3700\n",
            "Epoch 8931/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3706\n",
            "Epoch 8932/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3706\n",
            "Epoch 8933/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3693\n",
            "Epoch 8934/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3710\n",
            "Epoch 8935/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3688\n",
            "Epoch 8936/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3697\n",
            "Epoch 8937/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3671\n",
            "Epoch 8938/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3668 - val_loss: 0.3723\n",
            "Epoch 8939/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3713 - val_loss: 0.3704\n",
            "Epoch 8940/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3702 - val_loss: 0.3716\n",
            "Epoch 8941/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3690\n",
            "Epoch 8942/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3698\n",
            "Epoch 8943/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3715\n",
            "Epoch 8944/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3695\n",
            "Epoch 8945/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3708\n",
            "Epoch 8946/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3694\n",
            "Epoch 8947/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3719\n",
            "Epoch 8948/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3712 - val_loss: 0.3711\n",
            "Epoch 8949/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3753 - val_loss: 0.3689\n",
            "Epoch 8950/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3686\n",
            "Epoch 8951/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3680\n",
            "Epoch 8952/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3676 - val_loss: 0.3703\n",
            "Epoch 8953/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3711 - val_loss: 0.3690\n",
            "Epoch 8954/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3710\n",
            "Epoch 8955/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3734\n",
            "Epoch 8956/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3746 - val_loss: 0.3743\n",
            "Epoch 8957/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3740 - val_loss: 0.3696\n",
            "Epoch 8958/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3669\n",
            "Epoch 8959/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3684 - val_loss: 0.3697\n",
            "Epoch 8960/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3676\n",
            "Epoch 8961/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3701\n",
            "Epoch 8962/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3698\n",
            "Epoch 8963/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3684 - val_loss: 0.3694\n",
            "Epoch 8964/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3710\n",
            "Epoch 8965/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3724\n",
            "Epoch 8966/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3756 - val_loss: 0.3687\n",
            "Epoch 8967/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3686\n",
            "Epoch 8968/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3663\n",
            "Epoch 8969/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3699 - val_loss: 0.3681\n",
            "Epoch 8970/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3715\n",
            "Epoch 8971/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3748 - val_loss: 0.3702\n",
            "Epoch 8972/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3736\n",
            "Epoch 8973/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3717\n",
            "Epoch 8974/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3681\n",
            "Epoch 8975/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3696\n",
            "Epoch 8976/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3679\n",
            "Epoch 8977/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3718\n",
            "Epoch 8978/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3675\n",
            "Epoch 8979/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3697\n",
            "Epoch 8980/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3714\n",
            "Epoch 8981/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3699\n",
            "Epoch 8982/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3683\n",
            "Epoch 8983/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3703\n",
            "Epoch 8984/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3664\n",
            "Epoch 8985/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3702\n",
            "Epoch 8986/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3680\n",
            "Epoch 8987/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3690\n",
            "Epoch 8988/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3683 - val_loss: 0.3705\n",
            "Epoch 8989/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3711\n",
            "Epoch 8990/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3716\n",
            "Epoch 8991/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3739 - val_loss: 0.3715\n",
            "Epoch 8992/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3684\n",
            "Epoch 8993/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3696\n",
            "Epoch 8994/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3712 - val_loss: 0.3709\n",
            "Epoch 8995/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3717\n",
            "Epoch 8996/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3686\n",
            "Epoch 8997/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3719\n",
            "Epoch 8998/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3745 - val_loss: 0.3691\n",
            "Epoch 8999/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3723\n",
            "Epoch 9000/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3715\n",
            "Epoch 9001/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3739 - val_loss: 0.3700\n",
            "Epoch 9002/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3723 - val_loss: 0.3678\n",
            "Epoch 9003/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3685\n",
            "Epoch 9004/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3709\n",
            "Epoch 9005/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3714\n",
            "Epoch 9006/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3706\n",
            "Epoch 9007/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3721\n",
            "Epoch 9008/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3699\n",
            "Epoch 9009/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3696\n",
            "Epoch 9010/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3704\n",
            "Epoch 9011/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3689\n",
            "Epoch 9012/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3712\n",
            "Epoch 9013/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3715\n",
            "Epoch 9014/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3687\n",
            "Epoch 9015/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3713 - val_loss: 0.3690\n",
            "Epoch 9016/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3688 - val_loss: 0.3705\n",
            "Epoch 9017/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3702\n",
            "Epoch 9018/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.3697\n",
            "Epoch 9019/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3712\n",
            "Epoch 9020/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3697\n",
            "Epoch 9021/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3696 - val_loss: 0.3719\n",
            "Epoch 9022/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3696\n",
            "Epoch 9023/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3687\n",
            "Epoch 9024/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3713\n",
            "Epoch 9025/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3692\n",
            "Epoch 9026/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3705\n",
            "Epoch 9027/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3710\n",
            "Epoch 9028/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3689\n",
            "Epoch 9029/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3704\n",
            "Epoch 9030/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3697\n",
            "Epoch 9031/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3697\n",
            "Epoch 9032/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3718\n",
            "Epoch 9033/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3726\n",
            "Epoch 9034/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3695\n",
            "Epoch 9035/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3720\n",
            "Epoch 9036/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3708 - val_loss: 0.3696\n",
            "Epoch 9037/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3682\n",
            "Epoch 9038/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3719\n",
            "Epoch 9039/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3705\n",
            "Epoch 9040/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3706\n",
            "Epoch 9041/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3733 - val_loss: 0.3709\n",
            "Epoch 9042/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3728\n",
            "Epoch 9043/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3694\n",
            "Epoch 9044/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3708\n",
            "Epoch 9045/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3676\n",
            "Epoch 9046/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3709\n",
            "Epoch 9047/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3728\n",
            "Epoch 9048/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3682\n",
            "Epoch 9049/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3702\n",
            "Epoch 9050/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3720\n",
            "Epoch 9051/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3740 - val_loss: 0.3661\n",
            "Epoch 9052/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3696\n",
            "Epoch 9053/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3684\n",
            "Epoch 9054/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3709\n",
            "Epoch 9055/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3693\n",
            "Epoch 9056/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3690 - val_loss: 0.3711\n",
            "Epoch 9057/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3722\n",
            "Epoch 9058/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3699\n",
            "Epoch 9059/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3727\n",
            "Epoch 9060/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3693\n",
            "Epoch 9061/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3696\n",
            "Epoch 9062/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3698\n",
            "Epoch 9063/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3710\n",
            "Epoch 9064/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3716 - val_loss: 0.3699\n",
            "Epoch 9065/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.3682\n",
            "Epoch 9066/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3688 - val_loss: 0.3691\n",
            "Epoch 9067/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3710\n",
            "Epoch 9068/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3735 - val_loss: 0.3707\n",
            "Epoch 9069/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3702\n",
            "Epoch 9070/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3698 - val_loss: 0.3679\n",
            "Epoch 9071/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3704\n",
            "Epoch 9072/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3716 - val_loss: 0.3699\n",
            "Epoch 9073/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3719\n",
            "Epoch 9074/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3708\n",
            "Epoch 9075/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3684\n",
            "Epoch 9076/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3700 - val_loss: 0.3700\n",
            "Epoch 9077/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3685\n",
            "Epoch 9078/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3681 - val_loss: 0.3707\n",
            "Epoch 9079/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3705\n",
            "Epoch 9080/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3702\n",
            "Epoch 9081/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3710\n",
            "Epoch 9082/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3685\n",
            "Epoch 9083/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3719\n",
            "Epoch 9084/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3692\n",
            "Epoch 9085/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3675\n",
            "Epoch 9086/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3678 - val_loss: 0.3711\n",
            "Epoch 9087/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3709\n",
            "Epoch 9088/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3683\n",
            "Epoch 9089/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3710\n",
            "Epoch 9090/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3727\n",
            "Epoch 9091/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3694\n",
            "Epoch 9092/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3703\n",
            "Epoch 9093/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3698\n",
            "Epoch 9094/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3706\n",
            "Epoch 9095/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3713\n",
            "Epoch 9096/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3727 - val_loss: 0.3696\n",
            "Epoch 9097/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3704 - val_loss: 0.3688\n",
            "Epoch 9098/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3699\n",
            "Epoch 9099/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3706\n",
            "Epoch 9100/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3692 - val_loss: 0.3706\n",
            "Epoch 9101/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3715 - val_loss: 0.3698\n",
            "Epoch 9102/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3681\n",
            "Epoch 9103/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3688\n",
            "Epoch 9104/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3714 - val_loss: 0.3733\n",
            "Epoch 9105/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3701\n",
            "Epoch 9106/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3687\n",
            "Epoch 9107/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3696\n",
            "Epoch 9108/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3732 - val_loss: 0.3710\n",
            "Epoch 9109/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3701\n",
            "Epoch 9110/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3677\n",
            "Epoch 9111/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3691 - val_loss: 0.3705\n",
            "Epoch 9112/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3708 - val_loss: 0.3697\n",
            "Epoch 9113/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3718\n",
            "Epoch 9114/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3703\n",
            "Epoch 9115/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3687\n",
            "Epoch 9116/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3682\n",
            "Epoch 9117/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3676 - val_loss: 0.3711\n",
            "Epoch 9118/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3751 - val_loss: 0.3688\n",
            "Epoch 9119/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3676 - val_loss: 0.3724\n",
            "Epoch 9120/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3675\n",
            "Epoch 9121/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3714\n",
            "Epoch 9122/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3740 - val_loss: 0.3694\n",
            "Epoch 9123/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3700\n",
            "Epoch 9124/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3694\n",
            "Epoch 9125/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3701 - val_loss: 0.3724\n",
            "Epoch 9126/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3697\n",
            "Epoch 9127/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3725\n",
            "Epoch 9128/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3743 - val_loss: 0.3674\n",
            "Epoch 9129/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3702\n",
            "Epoch 9130/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3676\n",
            "Epoch 9131/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3698\n",
            "Epoch 9132/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3693\n",
            "Epoch 9133/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3679\n",
            "Epoch 9134/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3692\n",
            "Epoch 9135/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3716\n",
            "Epoch 9136/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3660\n",
            "Epoch 9137/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3682 - val_loss: 0.3718\n",
            "Epoch 9138/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3708\n",
            "Epoch 9139/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3731 - val_loss: 0.3703\n",
            "Epoch 9140/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3691\n",
            "Epoch 9141/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3712\n",
            "Epoch 9142/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3706\n",
            "Epoch 9143/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3691\n",
            "Epoch 9144/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3709\n",
            "Epoch 9145/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3707\n",
            "Epoch 9146/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3686\n",
            "Epoch 9147/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3712\n",
            "Epoch 9148/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3711\n",
            "Epoch 9149/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3750 - val_loss: 0.3699\n",
            "Epoch 9150/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3684\n",
            "Epoch 9151/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3684\n",
            "Epoch 9152/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3721\n",
            "Epoch 9153/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3712\n",
            "Epoch 9154/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3707\n",
            "Epoch 9155/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3697\n",
            "Epoch 9156/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3711\n",
            "Epoch 9157/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3688\n",
            "Epoch 9158/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3710\n",
            "Epoch 9159/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3688\n",
            "Epoch 9160/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3685 - val_loss: 0.3724\n",
            "Epoch 9161/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3691\n",
            "Epoch 9162/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3691\n",
            "Epoch 9163/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3683\n",
            "Epoch 9164/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3718\n",
            "Epoch 9165/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3717\n",
            "Epoch 9166/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3699 - val_loss: 0.3675\n",
            "Epoch 9167/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3700\n",
            "Epoch 9168/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3682 - val_loss: 0.3688\n",
            "Epoch 9169/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3715\n",
            "Epoch 9170/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3725 - val_loss: 0.3701\n",
            "Epoch 9171/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3678\n",
            "Epoch 9172/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3672 - val_loss: 0.3713\n",
            "Epoch 9173/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3731\n",
            "Epoch 9174/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3709\n",
            "Epoch 9175/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3754 - val_loss: 0.3678\n",
            "Epoch 9176/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3702\n",
            "Epoch 9177/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3722\n",
            "Epoch 9178/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3695\n",
            "Epoch 9179/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3726\n",
            "Epoch 9180/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3761 - val_loss: 0.3678\n",
            "Epoch 9181/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3730 - val_loss: 0.3697\n",
            "Epoch 9182/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3680\n",
            "Epoch 9183/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3691\n",
            "Epoch 9184/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3711\n",
            "Epoch 9185/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3726 - val_loss: 0.3699\n",
            "Epoch 9186/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3713\n",
            "Epoch 9187/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3697 - val_loss: 0.3681\n",
            "Epoch 9188/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3694\n",
            "Epoch 9189/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3690\n",
            "Epoch 9190/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3721\n",
            "Epoch 9191/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3693\n",
            "Epoch 9192/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3681 - val_loss: 0.3685\n",
            "Epoch 9193/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3715\n",
            "Epoch 9194/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3694\n",
            "Epoch 9195/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3730\n",
            "Epoch 9196/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3695\n",
            "Epoch 9197/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3707 - val_loss: 0.3683\n",
            "Epoch 9198/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3685\n",
            "Epoch 9199/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3708\n",
            "Epoch 9200/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3699 - val_loss: 0.3701\n",
            "Epoch 9201/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3668\n",
            "Epoch 9202/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3713\n",
            "Epoch 9203/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3714\n",
            "Epoch 9204/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3696\n",
            "Epoch 9205/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3702\n",
            "Epoch 9206/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3678\n",
            "Epoch 9207/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3712\n",
            "Epoch 9208/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3711\n",
            "Epoch 9209/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3684\n",
            "Epoch 9210/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3693\n",
            "Epoch 9211/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3707\n",
            "Epoch 9212/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3694\n",
            "Epoch 9213/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3706\n",
            "Epoch 9214/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3696\n",
            "Epoch 9215/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3695\n",
            "Epoch 9216/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3740 - val_loss: 0.3723\n",
            "Epoch 9217/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3692\n",
            "Epoch 9218/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3718\n",
            "Epoch 9219/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3686\n",
            "Epoch 9220/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3712\n",
            "Epoch 9221/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3700 - val_loss: 0.3709\n",
            "Epoch 9222/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3714 - val_loss: 0.3707\n",
            "Epoch 9223/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3695\n",
            "Epoch 9224/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3669\n",
            "Epoch 9225/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3735\n",
            "Epoch 9226/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3708\n",
            "Epoch 9227/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3727 - val_loss: 0.3711\n",
            "Epoch 9228/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3685\n",
            "Epoch 9229/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3691\n",
            "Epoch 9230/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3730 - val_loss: 0.3690\n",
            "Epoch 9231/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3673 - val_loss: 0.3703\n",
            "Epoch 9232/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3684\n",
            "Epoch 9233/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3694\n",
            "Epoch 9234/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3701\n",
            "Epoch 9235/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3743\n",
            "Epoch 9236/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3751 - val_loss: 0.3671\n",
            "Epoch 9237/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3706\n",
            "Epoch 9238/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3713\n",
            "Epoch 9239/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3738 - val_loss: 0.3723\n",
            "Epoch 9240/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3740 - val_loss: 0.3681\n",
            "Epoch 9241/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3684\n",
            "Epoch 9242/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3708\n",
            "Epoch 9243/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3718\n",
            "Epoch 9244/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3755 - val_loss: 0.3689\n",
            "Epoch 9245/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3686 - val_loss: 0.3712\n",
            "Epoch 9246/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3669\n",
            "Epoch 9247/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3696 - val_loss: 0.3712\n",
            "Epoch 9248/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3712\n",
            "Epoch 9249/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3732\n",
            "Epoch 9250/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3711\n",
            "Epoch 9251/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3737 - val_loss: 0.3680\n",
            "Epoch 9252/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3681\n",
            "Epoch 9253/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3671 - val_loss: 0.3703\n",
            "Epoch 9254/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3710\n",
            "Epoch 9255/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3703\n",
            "Epoch 9256/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3697\n",
            "Epoch 9257/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3730\n",
            "Epoch 9258/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3681\n",
            "Epoch 9259/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3705 - val_loss: 0.3719\n",
            "Epoch 9260/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3699\n",
            "Epoch 9261/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3699 - val_loss: 0.3681\n",
            "Epoch 9262/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3694\n",
            "Epoch 9263/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3691\n",
            "Epoch 9264/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3706\n",
            "Epoch 9265/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3691\n",
            "Epoch 9266/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3690\n",
            "Epoch 9267/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3708\n",
            "Epoch 9268/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3707\n",
            "Epoch 9269/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3689\n",
            "Epoch 9270/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3698\n",
            "Epoch 9271/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3693\n",
            "Epoch 9272/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3684 - val_loss: 0.3684\n",
            "Epoch 9273/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3706\n",
            "Epoch 9274/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3702\n",
            "Epoch 9275/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.3696\n",
            "Epoch 9276/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3690\n",
            "Epoch 9277/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3672\n",
            "Epoch 9278/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3719\n",
            "Epoch 9279/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3729\n",
            "Epoch 9280/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3682\n",
            "Epoch 9281/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3691\n",
            "Epoch 9282/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3695\n",
            "Epoch 9283/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3730 - val_loss: 0.3694\n",
            "Epoch 9284/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3675\n",
            "Epoch 9285/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3696\n",
            "Epoch 9286/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3698 - val_loss: 0.3703\n",
            "Epoch 9287/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3717 - val_loss: 0.3713\n",
            "Epoch 9288/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3733\n",
            "Epoch 9289/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3674\n",
            "Epoch 9290/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3702\n",
            "Epoch 9291/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3691 - val_loss: 0.3686\n",
            "Epoch 9292/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3700\n",
            "Epoch 9293/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3689\n",
            "Epoch 9294/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3703\n",
            "Epoch 9295/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3684\n",
            "Epoch 9296/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3720\n",
            "Epoch 9297/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3741 - val_loss: 0.3690\n",
            "Epoch 9298/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3719 - val_loss: 0.3693\n",
            "Epoch 9299/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3677\n",
            "Epoch 9300/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3668 - val_loss: 0.3712\n",
            "Epoch 9301/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3714\n",
            "Epoch 9302/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3760 - val_loss: 0.3703\n",
            "Epoch 9303/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3684\n",
            "Epoch 9304/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3697\n",
            "Epoch 9305/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3704\n",
            "Epoch 9306/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3704\n",
            "Epoch 9307/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3730\n",
            "Epoch 9308/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3682\n",
            "Epoch 9309/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3713\n",
            "Epoch 9310/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3710 - val_loss: 0.3700\n",
            "Epoch 9311/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3715\n",
            "Epoch 9312/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3709\n",
            "Epoch 9313/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3715\n",
            "Epoch 9314/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3711\n",
            "Epoch 9315/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3696\n",
            "Epoch 9316/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3703\n",
            "Epoch 9317/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3698\n",
            "Epoch 9318/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3691\n",
            "Epoch 9319/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3680\n",
            "Epoch 9320/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3709 - val_loss: 0.3701\n",
            "Epoch 9321/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3707\n",
            "Epoch 9322/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3692\n",
            "Epoch 9323/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3702\n",
            "Epoch 9324/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3724\n",
            "Epoch 9325/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3742 - val_loss: 0.3673\n",
            "Epoch 9326/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3709\n",
            "Epoch 9327/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3726 - val_loss: 0.3692\n",
            "Epoch 9328/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3704\n",
            "Epoch 9329/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3680\n",
            "Epoch 9330/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3667\n",
            "Epoch 9331/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3664 - val_loss: 0.3720\n",
            "Epoch 9332/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3701\n",
            "Epoch 9333/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3729 - val_loss: 0.3710\n",
            "Epoch 9334/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3738 - val_loss: 0.3742\n",
            "Epoch 9335/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3737 - val_loss: 0.3678\n",
            "Epoch 9336/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3701\n",
            "Epoch 9337/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3752 - val_loss: 0.3675\n",
            "Epoch 9338/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3672 - val_loss: 0.3719\n",
            "Epoch 9339/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3728 - val_loss: 0.3662\n",
            "Epoch 9340/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3701\n",
            "Epoch 9341/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3717\n",
            "Epoch 9342/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3717\n",
            "Epoch 9343/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3756 - val_loss: 0.3678\n",
            "Epoch 9344/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3679 - val_loss: 0.3679\n",
            "Epoch 9345/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3723\n",
            "Epoch 9346/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3687\n",
            "Epoch 9347/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3692\n",
            "Epoch 9348/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3717\n",
            "Epoch 9349/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3695\n",
            "Epoch 9350/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3693 - val_loss: 0.3700\n",
            "Epoch 9351/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3672\n",
            "Epoch 9352/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3662\n",
            "Epoch 9353/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3705\n",
            "Epoch 9354/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3697\n",
            "Epoch 9355/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3679\n",
            "Epoch 9356/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3687\n",
            "Epoch 9357/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3692\n",
            "Epoch 9358/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3701\n",
            "Epoch 9359/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3683\n",
            "Epoch 9360/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3687\n",
            "Epoch 9361/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3711\n",
            "Epoch 9362/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.3694\n",
            "Epoch 9363/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3712\n",
            "Epoch 9364/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3672\n",
            "Epoch 9365/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3676 - val_loss: 0.3697\n",
            "Epoch 9366/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3704\n",
            "Epoch 9367/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3722\n",
            "Epoch 9368/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3706\n",
            "Epoch 9369/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3684 - val_loss: 0.3688\n",
            "Epoch 9370/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3697\n",
            "Epoch 9371/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3687\n",
            "Epoch 9372/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3704\n",
            "Epoch 9373/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3698\n",
            "Epoch 9374/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3695\n",
            "Epoch 9375/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3685\n",
            "Epoch 9376/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3687\n",
            "Epoch 9377/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3691 - val_loss: 0.3695\n",
            "Epoch 9378/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3689\n",
            "Epoch 9379/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3675 - val_loss: 0.3733\n",
            "Epoch 9380/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3702\n",
            "Epoch 9381/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3677 - val_loss: 0.3717\n",
            "Epoch 9382/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3682\n",
            "Epoch 9383/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3690\n",
            "Epoch 9384/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3695 - val_loss: 0.3729\n",
            "Epoch 9385/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3697\n",
            "Epoch 9386/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3698\n",
            "Epoch 9387/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3692\n",
            "Epoch 9388/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3699\n",
            "Epoch 9389/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3694 - val_loss: 0.3708\n",
            "Epoch 9390/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3729 - val_loss: 0.3696\n",
            "Epoch 9391/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3676\n",
            "Epoch 9392/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3698 - val_loss: 0.3680\n",
            "Epoch 9393/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3686 - val_loss: 0.3731\n",
            "Epoch 9394/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3708\n",
            "Epoch 9395/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3726 - val_loss: 0.3698\n",
            "Epoch 9396/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3711 - val_loss: 0.3678\n",
            "Epoch 9397/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3695\n",
            "Epoch 9398/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3700\n",
            "Epoch 9399/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3718\n",
            "Epoch 9400/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3682\n",
            "Epoch 9401/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3695\n",
            "Epoch 9402/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3711\n",
            "Epoch 9403/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3693\n",
            "Epoch 9404/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3686 - val_loss: 0.3711\n",
            "Epoch 9405/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3689 - val_loss: 0.3703\n",
            "Epoch 9406/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3704 - val_loss: 0.3709\n",
            "Epoch 9407/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3718 - val_loss: 0.3716\n",
            "Epoch 9408/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3740 - val_loss: 0.3702\n",
            "Epoch 9409/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3683\n",
            "Epoch 9410/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3676\n",
            "Epoch 9411/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3686 - val_loss: 0.3707\n",
            "Epoch 9412/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3707\n",
            "Epoch 9413/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3725\n",
            "Epoch 9414/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3689 - val_loss: 0.3714\n",
            "Epoch 9415/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3716 - val_loss: 0.3699\n",
            "Epoch 9416/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3716\n",
            "Epoch 9417/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3702\n",
            "Epoch 9418/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3687\n",
            "Epoch 9419/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3691 - val_loss: 0.3703\n",
            "Epoch 9420/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3705\n",
            "Epoch 9421/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3705\n",
            "Epoch 9422/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3691\n",
            "Epoch 9423/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3709\n",
            "Epoch 9424/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3723\n",
            "Epoch 9425/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3745 - val_loss: 0.3688\n",
            "Epoch 9426/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3705\n",
            "Epoch 9427/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3696\n",
            "Epoch 9428/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3697\n",
            "Epoch 9429/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3670\n",
            "Epoch 9430/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3694\n",
            "Epoch 9431/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3711\n",
            "Epoch 9432/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3704 - val_loss: 0.3710\n",
            "Epoch 9433/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3716 - val_loss: 0.3701\n",
            "Epoch 9434/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3686\n",
            "Epoch 9435/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3714\n",
            "Epoch 9436/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3693 - val_loss: 0.3720\n",
            "Epoch 9437/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3697\n",
            "Epoch 9438/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3721\n",
            "Epoch 9439/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3689\n",
            "Epoch 9440/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3690\n",
            "Epoch 9441/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3687\n",
            "Epoch 9442/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3700\n",
            "Epoch 9443/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3707\n",
            "Epoch 9444/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3734 - val_loss: 0.3683\n",
            "Epoch 9445/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3691\n",
            "Epoch 9446/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3723 - val_loss: 0.3712\n",
            "Epoch 9447/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3703\n",
            "Epoch 9448/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3718\n",
            "Epoch 9449/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3664\n",
            "Epoch 9450/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3659 - val_loss: 0.3725\n",
            "Epoch 9451/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3704\n",
            "Epoch 9452/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3696\n",
            "Epoch 9453/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3705\n",
            "Epoch 9454/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3681\n",
            "Epoch 9455/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - val_loss: 0.3696\n",
            "Epoch 9456/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3693\n",
            "Epoch 9457/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3699\n",
            "Epoch 9458/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3737 - val_loss: 0.3710\n",
            "Epoch 9459/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3661\n",
            "Epoch 9460/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3696\n",
            "Epoch 9461/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3708\n",
            "Epoch 9462/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3687\n",
            "Epoch 9463/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3727 - val_loss: 0.3713\n",
            "Epoch 9464/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3683\n",
            "Epoch 9465/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3730\n",
            "Epoch 9466/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3695\n",
            "Epoch 9467/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3689\n",
            "Epoch 9468/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3696 - val_loss: 0.3707\n",
            "Epoch 9469/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3715\n",
            "Epoch 9470/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3669\n",
            "Epoch 9471/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3707\n",
            "Epoch 9472/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3680\n",
            "Epoch 9473/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3702\n",
            "Epoch 9474/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3689\n",
            "Epoch 9475/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3744\n",
            "Epoch 9476/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3777 - val_loss: 0.3700\n",
            "Epoch 9477/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3701\n",
            "Epoch 9478/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3698\n",
            "Epoch 9479/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3705\n",
            "Epoch 9480/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3682 - val_loss: 0.3684\n",
            "Epoch 9481/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3679\n",
            "Epoch 9482/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3690 - val_loss: 0.3699\n",
            "Epoch 9483/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3724 - val_loss: 0.3707\n",
            "Epoch 9484/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3681\n",
            "Epoch 9485/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3674 - val_loss: 0.3678\n",
            "Epoch 9486/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3672 - val_loss: 0.3707\n",
            "Epoch 9487/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3716\n",
            "Epoch 9488/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3709\n",
            "Epoch 9489/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3684\n",
            "Epoch 9490/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3667 - val_loss: 0.3704\n",
            "Epoch 9491/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3721\n",
            "Epoch 9492/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3683\n",
            "Epoch 9493/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3676\n",
            "Epoch 9494/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3699\n",
            "Epoch 9495/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3693\n",
            "Epoch 9496/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3708 - val_loss: 0.3692\n",
            "Epoch 9497/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3708\n",
            "Epoch 9498/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3676\n",
            "Epoch 9499/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3681 - val_loss: 0.3716\n",
            "Epoch 9500/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3678\n",
            "Epoch 9501/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3712\n",
            "Epoch 9502/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3741 - val_loss: 0.3681\n",
            "Epoch 9503/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3695\n",
            "Epoch 9504/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3714\n",
            "Epoch 9505/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3734 - val_loss: 0.3690\n",
            "Epoch 9506/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3677 - val_loss: 0.3696\n",
            "Epoch 9507/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3708\n",
            "Epoch 9508/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3718\n",
            "Epoch 9509/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3698\n",
            "Epoch 9510/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3682\n",
            "Epoch 9511/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3696\n",
            "Epoch 9512/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3679 - val_loss: 0.3687\n",
            "Epoch 9513/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3704\n",
            "Epoch 9514/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3688\n",
            "Epoch 9515/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3682\n",
            "Epoch 9516/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - val_loss: 0.3710\n",
            "Epoch 9517/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3694 - val_loss: 0.3709\n",
            "Epoch 9518/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3691\n",
            "Epoch 9519/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3693\n",
            "Epoch 9520/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3683\n",
            "Epoch 9521/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3702\n",
            "Epoch 9522/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3690\n",
            "Epoch 9523/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3693 - val_loss: 0.3701\n",
            "Epoch 9524/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3699\n",
            "Epoch 9525/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3688\n",
            "Epoch 9526/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3722\n",
            "Epoch 9527/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3698\n",
            "Epoch 9528/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3702 - val_loss: 0.3682\n",
            "Epoch 9529/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3683\n",
            "Epoch 9530/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3691 - val_loss: 0.3725\n",
            "Epoch 9531/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3693\n",
            "Epoch 9532/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3680\n",
            "Epoch 9533/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3683\n",
            "Epoch 9534/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3698\n",
            "Epoch 9535/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3730\n",
            "Epoch 9536/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3697\n",
            "Epoch 9537/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3695\n",
            "Epoch 9538/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3703 - val_loss: 0.3697\n",
            "Epoch 9539/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3692\n",
            "Epoch 9540/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3707\n",
            "Epoch 9541/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3696\n",
            "Epoch 9542/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3701\n",
            "Epoch 9543/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3685\n",
            "Epoch 9544/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3722\n",
            "Epoch 9545/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3741 - val_loss: 0.3705\n",
            "Epoch 9546/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3744 - val_loss: 0.3675\n",
            "Epoch 9547/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3705\n",
            "Epoch 9548/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3699\n",
            "Epoch 9549/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3678\n",
            "Epoch 9550/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3708\n",
            "Epoch 9551/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3687\n",
            "Epoch 9552/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3707\n",
            "Epoch 9553/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3704\n",
            "Epoch 9554/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 0.3703\n",
            "Epoch 9555/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3687\n",
            "Epoch 9556/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3712\n",
            "Epoch 9557/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3712\n",
            "Epoch 9558/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3699 - val_loss: 0.3716\n",
            "Epoch 9559/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3696\n",
            "Epoch 9560/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3672 - val_loss: 0.3731\n",
            "Epoch 9561/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3720 - val_loss: 0.3712\n",
            "Epoch 9562/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3693\n",
            "Epoch 9563/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3679\n",
            "Epoch 9564/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3709\n",
            "Epoch 9565/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3685\n",
            "Epoch 9566/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3712\n",
            "Epoch 9567/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3692\n",
            "Epoch 9568/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3709\n",
            "Epoch 9569/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3710 - val_loss: 0.3680\n",
            "Epoch 9570/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3694 - val_loss: 0.3670\n",
            "Epoch 9571/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3669 - val_loss: 0.3710\n",
            "Epoch 9572/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3704 - val_loss: 0.3721\n",
            "Epoch 9573/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3703\n",
            "Epoch 9574/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3684\n",
            "Epoch 9575/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3686 - val_loss: 0.3722\n",
            "Epoch 9576/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3712\n",
            "Epoch 9577/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3672\n",
            "Epoch 9578/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3690\n",
            "Epoch 9579/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3687\n",
            "Epoch 9580/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3699 - val_loss: 0.3698\n",
            "Epoch 9581/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3683 - val_loss: 0.3687\n",
            "Epoch 9582/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3708\n",
            "Epoch 9583/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3718 - val_loss: 0.3697\n",
            "Epoch 9584/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3689\n",
            "Epoch 9585/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3692\n",
            "Epoch 9586/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3698\n",
            "Epoch 9587/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3699\n",
            "Epoch 9588/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3713\n",
            "Epoch 9589/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3695\n",
            "Epoch 9590/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3688\n",
            "Epoch 9591/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3689 - val_loss: 0.3720\n",
            "Epoch 9592/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3687\n",
            "Epoch 9593/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3702\n",
            "Epoch 9594/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3720 - val_loss: 0.3689\n",
            "Epoch 9595/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3709\n",
            "Epoch 9596/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3702\n",
            "Epoch 9597/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3697\n",
            "Epoch 9598/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3698\n",
            "Epoch 9599/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3696\n",
            "Epoch 9600/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3694\n",
            "Epoch 9601/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3726\n",
            "Epoch 9602/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3671\n",
            "Epoch 9603/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3695 - val_loss: 0.3696\n",
            "Epoch 9604/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3707\n",
            "Epoch 9605/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3685\n",
            "Epoch 9606/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3702\n",
            "Epoch 9607/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3693\n",
            "Epoch 9608/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3691\n",
            "Epoch 9609/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3685 - val_loss: 0.3683\n",
            "Epoch 9610/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3669\n",
            "Epoch 9611/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3703\n",
            "Epoch 9612/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3686 - val_loss: 0.3723\n",
            "Epoch 9613/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.3720\n",
            "Epoch 9614/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3688\n",
            "Epoch 9615/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3694\n",
            "Epoch 9616/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3679\n",
            "Epoch 9617/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3716\n",
            "Epoch 9618/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3716\n",
            "Epoch 9619/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3690\n",
            "Epoch 9620/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3687\n",
            "Epoch 9621/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3683 - val_loss: 0.3692\n",
            "Epoch 9622/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3687\n",
            "Epoch 9623/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.3684\n",
            "Epoch 9624/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3732\n",
            "Epoch 9625/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3724 - val_loss: 0.3681\n",
            "Epoch 9626/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3708\n",
            "Epoch 9627/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3680 - val_loss: 0.3711\n",
            "Epoch 9628/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3706 - val_loss: 0.3694\n",
            "Epoch 9629/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3697\n",
            "Epoch 9630/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3709\n",
            "Epoch 9631/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3690\n",
            "Epoch 9632/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3685 - val_loss: 0.3674\n",
            "Epoch 9633/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3696\n",
            "Epoch 9634/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3695\n",
            "Epoch 9635/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.3683\n",
            "Epoch 9636/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3701\n",
            "Epoch 9637/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3717\n",
            "Epoch 9638/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3678\n",
            "Epoch 9639/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3684\n",
            "Epoch 9640/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3717\n",
            "Epoch 9641/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3708\n",
            "Epoch 9642/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3687\n",
            "Epoch 9643/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3687\n",
            "Epoch 9644/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3677\n",
            "Epoch 9645/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3706 - val_loss: 0.3687\n",
            "Epoch 9646/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3700 - val_loss: 0.3732\n",
            "Epoch 9647/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3748 - val_loss: 0.3693\n",
            "Epoch 9648/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3720 - val_loss: 0.3694\n",
            "Epoch 9649/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3670\n",
            "Epoch 9650/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3700\n",
            "Epoch 9651/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3710\n",
            "Epoch 9652/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3703\n",
            "Epoch 9653/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3693\n",
            "Epoch 9654/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3675\n",
            "Epoch 9655/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3680\n",
            "Epoch 9656/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3697 - val_loss: 0.3732\n",
            "Epoch 9657/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3725 - val_loss: 0.3708\n",
            "Epoch 9658/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3670\n",
            "Epoch 9659/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3715\n",
            "Epoch 9660/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3695\n",
            "Epoch 9661/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3705 - val_loss: 0.3699\n",
            "Epoch 9662/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3689\n",
            "Epoch 9663/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3681 - val_loss: 0.3695\n",
            "Epoch 9664/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3684\n",
            "Epoch 9665/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3698\n",
            "Epoch 9666/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3719\n",
            "Epoch 9667/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3686\n",
            "Epoch 9668/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3696\n",
            "Epoch 9669/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3708 - val_loss: 0.3687\n",
            "Epoch 9670/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3695\n",
            "Epoch 9671/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3709\n",
            "Epoch 9672/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3708\n",
            "Epoch 9673/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3687\n",
            "Epoch 9674/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3695\n",
            "Epoch 9675/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3697\n",
            "Epoch 9676/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3695\n",
            "Epoch 9677/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3703\n",
            "Epoch 9678/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3721\n",
            "Epoch 9679/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3746 - val_loss: 0.3690\n",
            "Epoch 9680/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3696\n",
            "Epoch 9681/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3673\n",
            "Epoch 9682/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3689 - val_loss: 0.3714\n",
            "Epoch 9683/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3702\n",
            "Epoch 9684/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3700\n",
            "Epoch 9685/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3686\n",
            "Epoch 9686/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3704\n",
            "Epoch 9687/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3714\n",
            "Epoch 9688/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3716\n",
            "Epoch 9689/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3690\n",
            "Epoch 9690/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3758 - val_loss: 0.3675\n",
            "Epoch 9691/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3717\n",
            "Epoch 9692/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3681\n",
            "Epoch 9693/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3692\n",
            "Epoch 9694/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3703 - val_loss: 0.3687\n",
            "Epoch 9695/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3691 - val_loss: 0.3696\n",
            "Epoch 9696/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3714\n",
            "Epoch 9697/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3688\n",
            "Epoch 9698/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3700\n",
            "Epoch 9699/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3680\n",
            "Epoch 9700/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3693 - val_loss: 0.3706\n",
            "Epoch 9701/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3741 - val_loss: 0.3690\n",
            "Epoch 9702/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3713\n",
            "Epoch 9703/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3704\n",
            "Epoch 9704/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3715\n",
            "Epoch 9705/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3732 - val_loss: 0.3708\n",
            "Epoch 9706/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3703\n",
            "Epoch 9707/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3679 - val_loss: 0.3693\n",
            "Epoch 9708/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3693\n",
            "Epoch 9709/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3678\n",
            "Epoch 9710/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - val_loss: 0.3677\n",
            "Epoch 9711/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3677 - val_loss: 0.3684\n",
            "Epoch 9712/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3727\n",
            "Epoch 9713/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3717 - val_loss: 0.3706\n",
            "Epoch 9714/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3690\n",
            "Epoch 9715/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3686\n",
            "Epoch 9716/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3707\n",
            "Epoch 9717/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3698\n",
            "Epoch 9718/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3709\n",
            "Epoch 9719/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3681\n",
            "Epoch 9720/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3663 - val_loss: 0.3715\n",
            "Epoch 9721/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3714\n",
            "Epoch 9722/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3693\n",
            "Epoch 9723/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3685\n",
            "Epoch 9724/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3725 - val_loss: 0.3689\n",
            "Epoch 9725/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3706\n",
            "Epoch 9726/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3701\n",
            "Epoch 9727/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3709 - val_loss: 0.3703\n",
            "Epoch 9728/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3706\n",
            "Epoch 9729/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3707\n",
            "Epoch 9730/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3690 - val_loss: 0.3718\n",
            "Epoch 9731/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3689\n",
            "Epoch 9732/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3704\n",
            "Epoch 9733/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3687\n",
            "Epoch 9734/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3694 - val_loss: 0.3696\n",
            "Epoch 9735/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3709 - val_loss: 0.3685\n",
            "Epoch 9736/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3718 - val_loss: 0.3699\n",
            "Epoch 9737/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3683\n",
            "Epoch 9738/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3692\n",
            "Epoch 9739/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3682\n",
            "Epoch 9740/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3683 - val_loss: 0.3696\n",
            "Epoch 9741/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3715\n",
            "Epoch 9742/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3738 - val_loss: 0.3682\n",
            "Epoch 9743/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3684 - val_loss: 0.3723\n",
            "Epoch 9744/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3712\n",
            "Epoch 9745/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3706\n",
            "Epoch 9746/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3669\n",
            "Epoch 9747/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3672 - val_loss: 0.3679\n",
            "Epoch 9748/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3726\n",
            "Epoch 9749/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3731 - val_loss: 0.3701\n",
            "Epoch 9750/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3730 - val_loss: 0.3720\n",
            "Epoch 9751/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3721\n",
            "Epoch 9752/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3684\n",
            "Epoch 9753/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3700\n",
            "Epoch 9754/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3692\n",
            "Epoch 9755/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3701 - val_loss: 0.3723\n",
            "Epoch 9756/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3701\n",
            "Epoch 9757/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3729 - val_loss: 0.3695\n",
            "Epoch 9758/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3693 - val_loss: 0.3696\n",
            "Epoch 9759/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3723 - val_loss: 0.3667\n",
            "Epoch 9760/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3709\n",
            "Epoch 9761/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3707 - val_loss: 0.3688\n",
            "Epoch 9762/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3710\n",
            "Epoch 9763/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3679\n",
            "Epoch 9764/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3685 - val_loss: 0.3734\n",
            "Epoch 9765/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3757 - val_loss: 0.3688\n",
            "Epoch 9766/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3699\n",
            "Epoch 9767/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3732 - val_loss: 0.3701\n",
            "Epoch 9768/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3689 - val_loss: 0.3694\n",
            "Epoch 9769/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3674\n",
            "Epoch 9770/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3688 - val_loss: 0.3702\n",
            "Epoch 9771/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3697\n",
            "Epoch 9772/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3709\n",
            "Epoch 9773/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3696 - val_loss: 0.3687\n",
            "Epoch 9774/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3675 - val_loss: 0.3707\n",
            "Epoch 9775/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3720 - val_loss: 0.3729\n",
            "Epoch 9776/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3696\n",
            "Epoch 9777/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3704 - val_loss: 0.3693\n",
            "Epoch 9778/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3691\n",
            "Epoch 9779/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3707\n",
            "Epoch 9780/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3705 - val_loss: 0.3706\n",
            "Epoch 9781/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3709 - val_loss: 0.3682\n",
            "Epoch 9782/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3703\n",
            "Epoch 9783/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3703\n",
            "Epoch 9784/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3697\n",
            "Epoch 9785/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3694\n",
            "Epoch 9786/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3688 - val_loss: 0.3700\n",
            "Epoch 9787/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3699\n",
            "Epoch 9788/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3711\n",
            "Epoch 9789/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3737 - val_loss: 0.3687\n",
            "Epoch 9790/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3689\n",
            "Epoch 9791/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3705 - val_loss: 0.3710\n",
            "Epoch 9792/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3696\n",
            "Epoch 9793/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3690\n",
            "Epoch 9794/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3719\n",
            "Epoch 9795/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3714 - val_loss: 0.3683\n",
            "Epoch 9796/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3690\n",
            "Epoch 9797/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3703 - val_loss: 0.3694\n",
            "Epoch 9798/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3697 - val_loss: 0.3709\n",
            "Epoch 9799/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3723\n",
            "Epoch 9800/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3693\n",
            "Epoch 9801/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3665\n",
            "Epoch 9802/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3704\n",
            "Epoch 9803/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3683\n",
            "Epoch 9804/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3692\n",
            "Epoch 9805/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3693 - val_loss: 0.3708\n",
            "Epoch 9806/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 0.3698\n",
            "Epoch 9807/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 0.3717\n",
            "Epoch 9808/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3729 - val_loss: 0.3699\n",
            "Epoch 9809/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3752 - val_loss: 0.3672\n",
            "Epoch 9810/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3695\n",
            "Epoch 9811/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3718 - val_loss: 0.3705\n",
            "Epoch 9812/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3704\n",
            "Epoch 9813/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3679\n",
            "Epoch 9814/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3707\n",
            "Epoch 9815/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3712\n",
            "Epoch 9816/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3698\n",
            "Epoch 9817/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3677\n",
            "Epoch 9818/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3699 - val_loss: 0.3699\n",
            "Epoch 9819/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3704 - val_loss: 0.3709\n",
            "Epoch 9820/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3689 - val_loss: 0.3727\n",
            "Epoch 9821/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3727 - val_loss: 0.3690\n",
            "Epoch 9822/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3712 - val_loss: 0.3731\n",
            "Epoch 9823/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 0.3685\n",
            "Epoch 9824/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3687 - val_loss: 0.3694\n",
            "Epoch 9825/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3699 - val_loss: 0.3677\n",
            "Epoch 9826/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 0.3727\n",
            "Epoch 9827/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3731 - val_loss: 0.3667\n",
            "Epoch 9828/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3684 - val_loss: 0.3682\n",
            "Epoch 9829/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3678 - val_loss: 0.3727\n",
            "Epoch 9830/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3728 - val_loss: 0.3697\n",
            "Epoch 9831/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3692 - val_loss: 0.3671\n",
            "Epoch 9832/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3708\n",
            "Epoch 9833/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3686\n",
            "Epoch 9834/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3706\n",
            "Epoch 9835/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3712\n",
            "Epoch 9836/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3676\n",
            "Epoch 9837/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3709\n",
            "Epoch 9838/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3725\n",
            "Epoch 9839/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3720 - val_loss: 0.3731\n",
            "Epoch 9840/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3688\n",
            "Epoch 9841/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.3701\n",
            "Epoch 9842/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3697 - val_loss: 0.3680\n",
            "Epoch 9843/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3744\n",
            "Epoch 9844/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3686\n",
            "Epoch 9845/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3680\n",
            "Epoch 9846/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3698 - val_loss: 0.3723\n",
            "Epoch 9847/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3712 - val_loss: 0.3713\n",
            "Epoch 9848/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3716 - val_loss: 0.3700\n",
            "Epoch 9849/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3718 - val_loss: 0.3692\n",
            "Epoch 9850/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3707\n",
            "Epoch 9851/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3708 - val_loss: 0.3720\n",
            "Epoch 9852/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3686\n",
            "Epoch 9853/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3688\n",
            "Epoch 9854/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3704 - val_loss: 0.3698\n",
            "Epoch 9855/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3676\n",
            "Epoch 9856/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3677 - val_loss: 0.3705\n",
            "Epoch 9857/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3689 - val_loss: 0.3714\n",
            "Epoch 9858/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3683\n",
            "Epoch 9859/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3678 - val_loss: 0.3676\n",
            "Epoch 9860/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3708\n",
            "Epoch 9861/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3712 - val_loss: 0.3699\n",
            "Epoch 9862/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3701\n",
            "Epoch 9863/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3704 - val_loss: 0.3704\n",
            "Epoch 9864/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3705\n",
            "Epoch 9865/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3705\n",
            "Epoch 9866/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3743 - val_loss: 0.3692\n",
            "Epoch 9867/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.3677\n",
            "Epoch 9868/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3693\n",
            "Epoch 9869/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3690\n",
            "Epoch 9870/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3701\n",
            "Epoch 9871/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3695 - val_loss: 0.3726\n",
            "Epoch 9872/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.3686\n",
            "Epoch 9873/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3687\n",
            "Epoch 9874/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3696 - val_loss: 0.3696\n",
            "Epoch 9875/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3725\n",
            "Epoch 9876/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3704\n",
            "Epoch 9877/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3708\n",
            "Epoch 9878/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.3682\n",
            "Epoch 9879/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3702 - val_loss: 0.3680\n",
            "Epoch 9880/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3678 - val_loss: 0.3713\n",
            "Epoch 9881/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3725 - val_loss: 0.3683\n",
            "Epoch 9882/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3676 - val_loss: 0.3701\n",
            "Epoch 9883/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3701 - val_loss: 0.3706\n",
            "Epoch 9884/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.3728\n",
            "Epoch 9885/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3742 - val_loss: 0.3699\n",
            "Epoch 9886/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3713 - val_loss: 0.3685\n",
            "Epoch 9887/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3707\n",
            "Epoch 9888/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3727\n",
            "Epoch 9889/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3710\n",
            "Epoch 9890/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3748 - val_loss: 0.3704\n",
            "Epoch 9891/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3698 - val_loss: 0.3694\n",
            "Epoch 9892/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.3706\n",
            "Epoch 9893/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3675 - val_loss: 0.3697\n",
            "Epoch 9894/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3714\n",
            "Epoch 9895/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3685\n",
            "Epoch 9896/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3695 - val_loss: 0.3731\n",
            "Epoch 9897/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3717 - val_loss: 0.3718\n",
            "Epoch 9898/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3699\n",
            "Epoch 9899/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3711\n",
            "Epoch 9900/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.3701\n",
            "Epoch 9901/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3698\n",
            "Epoch 9902/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3696\n",
            "Epoch 9903/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3703\n",
            "Epoch 9904/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3715 - val_loss: 0.3695\n",
            "Epoch 9905/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3699\n",
            "Epoch 9906/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3703\n",
            "Epoch 9907/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3702\n",
            "Epoch 9908/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3724 - val_loss: 0.3685\n",
            "Epoch 9909/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3724 - val_loss: 0.3689\n",
            "Epoch 9910/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3700\n",
            "Epoch 9911/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3683 - val_loss: 0.3699\n",
            "Epoch 9912/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3701 - val_loss: 0.3708\n",
            "Epoch 9913/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3735 - val_loss: 0.3687\n",
            "Epoch 9914/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3699\n",
            "Epoch 9915/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3708 - val_loss: 0.3694\n",
            "Epoch 9916/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3702 - val_loss: 0.3705\n",
            "Epoch 9917/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3686\n",
            "Epoch 9918/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3719 - val_loss: 0.3702\n",
            "Epoch 9919/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3685 - val_loss: 0.3693\n",
            "Epoch 9920/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3693 - val_loss: 0.3695\n",
            "Epoch 9921/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3698 - val_loss: 0.3709\n",
            "Epoch 9922/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3744 - val_loss: 0.3692\n",
            "Epoch 9923/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 0.3697\n",
            "Epoch 9924/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.3692\n",
            "Epoch 9925/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 0.3710\n",
            "Epoch 9926/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.3696\n",
            "Epoch 9927/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3681 - val_loss: 0.3711\n",
            "Epoch 9928/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3700 - val_loss: 0.3704\n",
            "Epoch 9929/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3707\n",
            "Epoch 9930/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3712\n",
            "Epoch 9931/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3737 - val_loss: 0.3677\n",
            "Epoch 9932/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3682 - val_loss: 0.3698\n",
            "Epoch 9933/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3711 - val_loss: 0.3676\n",
            "Epoch 9934/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3720\n",
            "Epoch 9935/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3708\n",
            "Epoch 9936/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - val_loss: 0.3712\n",
            "Epoch 9937/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3723 - val_loss: 0.3688\n",
            "Epoch 9938/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3715 - val_loss: 0.3697\n",
            "Epoch 9939/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3702 - val_loss: 0.3712\n",
            "Epoch 9940/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3715 - val_loss: 0.3672\n",
            "Epoch 9941/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3665 - val_loss: 0.3699\n",
            "Epoch 9942/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3728 - val_loss: 0.3680\n",
            "Epoch 9943/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3728\n",
            "Epoch 9944/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3728 - val_loss: 0.3683\n",
            "Epoch 9945/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3708 - val_loss: 0.3697\n",
            "Epoch 9946/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3698 - val_loss: 0.3732\n",
            "Epoch 9947/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3682\n",
            "Epoch 9948/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3675 - val_loss: 0.3695\n",
            "Epoch 9949/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3722 - val_loss: 0.3727\n",
            "Epoch 9950/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3711 - val_loss: 0.3676\n",
            "Epoch 9951/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3688 - val_loss: 0.3732\n",
            "Epoch 9952/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3742 - val_loss: 0.3678\n",
            "Epoch 9953/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3701 - val_loss: 0.3716\n",
            "Epoch 9954/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3706 - val_loss: 0.3697\n",
            "Epoch 9955/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3734 - val_loss: 0.3693\n",
            "Epoch 9956/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3746 - val_loss: 0.3696\n",
            "Epoch 9957/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.3702\n",
            "Epoch 9958/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3710 - val_loss: 0.3712\n",
            "Epoch 9959/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3706 - val_loss: 0.3692\n",
            "Epoch 9960/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3706 - val_loss: 0.3677\n",
            "Epoch 9961/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3702 - val_loss: 0.3721\n",
            "Epoch 9962/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 0.3714\n",
            "Epoch 9963/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3716 - val_loss: 0.3700\n",
            "Epoch 9964/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3724 - val_loss: 0.3715\n",
            "Epoch 9965/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3691\n",
            "Epoch 9966/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3705 - val_loss: 0.3693\n",
            "Epoch 9967/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3691 - val_loss: 0.3687\n",
            "Epoch 9968/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3698 - val_loss: 0.3703\n",
            "Epoch 9969/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3703 - val_loss: 0.3707\n",
            "Epoch 9970/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3692 - val_loss: 0.3718\n",
            "Epoch 9971/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3744 - val_loss: 0.3683\n",
            "Epoch 9972/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3710 - val_loss: 0.3689\n",
            "Epoch 9973/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 0.3702\n",
            "Epoch 9974/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3718 - val_loss: 0.3701\n",
            "Epoch 9975/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3708 - val_loss: 0.3676\n",
            "Epoch 9976/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3676 - val_loss: 0.3706\n",
            "Epoch 9977/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3712 - val_loss: 0.3682\n",
            "Epoch 9978/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3672 - val_loss: 0.3714\n",
            "Epoch 9979/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3723 - val_loss: 0.3700\n",
            "Epoch 9980/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3713 - val_loss: 0.3691\n",
            "Epoch 9981/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3681 - val_loss: 0.3687\n",
            "Epoch 9982/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3687 - val_loss: 0.3707\n",
            "Epoch 9983/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3701 - val_loss: 0.3727\n",
            "Epoch 9984/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - val_loss: 0.3698\n",
            "Epoch 9985/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3687 - val_loss: 0.3705\n",
            "Epoch 9986/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3684 - val_loss: 0.3664\n",
            "Epoch 9987/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3691 - val_loss: 0.3712\n",
            "Epoch 9988/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3728 - val_loss: 0.3705\n",
            "Epoch 9989/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3710 - val_loss: 0.3697\n",
            "Epoch 9990/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3733 - val_loss: 0.3664\n",
            "Epoch 9991/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.3707\n",
            "Epoch 9992/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3709 - val_loss: 0.3685\n",
            "Epoch 9993/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3707 - val_loss: 0.3689\n",
            "Epoch 9994/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3697\n",
            "Epoch 9995/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3718 - val_loss: 0.3692\n",
            "Epoch 9996/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3682 - val_loss: 0.3692\n",
            "Epoch 9997/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3694 - val_loss: 0.3682\n",
            "Epoch 9998/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3684 - val_loss: 0.3712\n",
            "Epoch 9999/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3726 - val_loss: 0.3722\n",
            "Epoch 10000/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3706 - val_loss: 0.3712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3397fcb090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvNc1KTFTYw7"
      },
      "source": [
        "def key_consine_similarity(tupple): \n",
        "  return tupple[1] \n",
        "def get_computed_similarities(vectors, predicted_vectors, reverse=False): \n",
        "  data_size = len(vectors) \n",
        "  cosine_similarities = [] \n",
        "  for i in range(data_size): \n",
        "    cosine_sim_val = (1 - cosine(vectors[i], predicted_vectors[i])) \n",
        "    cosine_similarities.append((i, cosine_sim_val)) \n",
        "  return sorted(cosine_similarities, key=key_consine_similarity, reverse=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozoYZc-2XdRp"
      },
      "source": [
        "def display_top_n(sorted_cosine_similarities, n=5): \n",
        "  for i in range(n): \n",
        "    index, consine_sim_val = sorted_cosine_similarities[i] \n",
        "    print('Subject: ', email_df.iloc[index, 0]) \n",
        "    print('Cosine Sim Val :', consine_sim_val) \n",
        "    print('----------------------------------') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiri4MYcXyGe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "22c10019-ffc1-4909-b8f0-3436480ad61b"
      },
      "source": [
        "# For normal process \n",
        "X1_dense = X_PCA \n",
        "X2_dense = np.concatenate((X1_dense, topic_df),axis=1) \n",
        "print(X1_dense.shape) \n",
        "print(X2_dense.shape)\n",
        "predicted_vectors = autoencoder.predict(X2_dense) \n",
        "mse = np.mean(np.power(X2_dense - predicted_vectors, 2), axis=1)\n",
        "error_df = pd.DataFrame({'reconstruction_error': mse})\n",
        "error_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 200)\n",
            "(5084, 230)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reconstruction_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5084.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.371161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.144513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.018380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.275169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.354693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.455845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.055469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reconstruction_error\n",
              "count           5084.000000\n",
              "mean               0.371161\n",
              "std                0.144513\n",
              "min                0.018380\n",
              "25%                0.275169\n",
              "50%                0.354693\n",
              "75%                0.455845\n",
              "max                1.055469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkN3vT21bPh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e17ab32-cc52-42fc-d56c-73622adbeb94"
      },
      "source": [
        "X1_anomaly_PCA = np.concatenate((X_anomaly_PCA, topic_df_anomaly),axis=1) \n",
        "print(X1_anomaly_PCA.shape) \n",
        "X2_dense = np.concatenate((X2_dense, X1_anomaly_PCA),axis=0) \n",
        "print(X2_dense.shape) \n",
        "predicted_vectors = autoencoder.predict(X2_dense) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 230)\n",
            "(5093, 230)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suxXbj6XzeHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de099201-585d-45d7-a0b5-9b58e3e7d7bc"
      },
      "source": [
        "data_size = len(predicted_vectors) \n",
        "cosine_similarities = [] \n",
        "for i in range(data_size): \n",
        "  cosine_sim_val = (1 - cosine(X2_dense[i], predicted_vectors[i])) \n",
        "  cosine_similarities.append((i, cosine_sim_val)) \n",
        "\n",
        "#cosine_similarities = pd.DataFrame(cosine_similarities, columns=rnumi, 'Cos_Sim']) \n",
        "#coords = PCA(n_components=2).fit_transform(predicted_vectors) \n",
        "df3 = X_train[['Subject', 'Body', 'Body_Original','From']] \n",
        "s = pd.Series([16941,16942,16943,16944,16945,16946,16947,16948,16949]) \n",
        "anomaly_df.set_index(s, inplace=True) \n",
        "df3 = pd.concat([df3, anomaly_df[['Subject','Body', 'Body_Original','From']]], axis=0) \n",
        "df3.reset_index(level=0, inplace=True) \n",
        "print(df3.shape) \n",
        "#print(len(coords)) \n",
        "print(len(cosine_similarities)) \n",
        "df3 = np.concatenate([df3, cosine_similarities], axis=1) \n",
        "df3 = pd.DataFrame(df3) \n",
        "df3.set_index(df3.columns[0], inplace=True) \n",
        "df3.rename(columns={df3.columns[0]:'Subject', \n",
        "                    df3.columns[1]:'Body', \n",
        "                    df3.columns[2]:'Body_Original', \n",
        "                    df3.columns[3]:'From',  \n",
        "                    df3.columns[4]:'Num',\n",
        "                    df3.columns[5]:'Cos_Sim'}, inplace=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5093, 5)\n",
            "5093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo3dD-di1TGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5f89f8-fc0e-4aed-b186-48246b6cb38e"
      },
      "source": [
        "#X1_dense = X_copy.todense() \n",
        "X1_dense = X_PCA \n",
        "X1_dense = np.concatenate((X1_dense, topic_df),axis=1) \n",
        "#X1_anomaly = np.concatenate((X_anomaly, topic_df_anomaly),axis=1) \n",
        "#X1_dense = np.concatenate((X1_dense, X1_anomaly),axis=0) \n",
        "print(X1_dense.shape) \n",
        "predicted_vectors = autoencoder.predict(X1_dense) \n",
        "print('Top 5 unique emails') \n",
        "sorted_cosine_similarities = get_computed_similarities(vectors=X1_dense, predicted_vectors=predicted_vectors) \n",
        "display_top_n(sorted_cosine_similarities=sorted_cosine_similarities, n =5) \n",
        "df3.loc[df3['Subject'] == 'Test-Misconduct', 'Outlier'] = 'Y' \n",
        "df3.loc[df3['Subject'] != 'Test-Misconduct', 'Outlier'] = 'N' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5084, 230)\n",
            "Top 5 unique emails\n",
            "Subject:  kay.mann@enron.com\n",
            "Cosine Sim Val : 0.171354687102251\n",
            "----------------------------------\n",
            "Subject:  kay.mann@enron.com\n",
            "Cosine Sim Val : 0.2754779752675892\n",
            "----------------------------------\n",
            "Subject:  kay.mann@enron.com\n",
            "Cosine Sim Val : 0.29589220934332827\n",
            "----------------------------------\n",
            "Subject:  kay.mann@enron.com\n",
            "Cosine Sim Val : 0.3131562195629938\n",
            "----------------------------------\n",
            "Subject:  kay.mann@enron.com\n",
            "Cosine Sim Val : 0.3131562195629938\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJnvJEJ116Zz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "58cb0727-7590-4b93-f6e6-203891648efa"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(10,7)})  \n",
        "g = sns.stripplot(x='Cos_Sim', y='Outlier', hue='Outlier', data=df3[['Cos_Sim','Outlier']], jitter=0.1, linewidth=0.1, palette=\"Set2\", size=10,) \n",
        "g. set_xlim([0,1]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWEcDo9lqZH4"
      },
      "source": [
        "### Reference:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fOP5rz2qZH6"
      },
      "source": [
        "1) https://towardsdatascience.com/applying-machine-learning-to-classify-an-unsupervised-text-document-e7bb6265f52\n",
        "\n",
        "2) http://rohitapte.com/2019/04/04/stylometric-analysis/\n",
        "\n",
        "3) https://www.tutorialspoint.com/python/python_extract_url_from_text.htm\n",
        "\n",
        "4) https://medium.comi@rnbrown/more-nlp-with-sklearns-countvectorizer-add577a0b8c8\n",
        "\n",
        "5) https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
        "\n",
        "6) https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
        "\n",
        "7) https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
        "\n",
        "8) https://medium.com/datadriveninvestor/unsupervised-outlier-detection-in-text-corpus-using-deep-learning-41d4284a04c8\n",
        "\n",
        "9) https://en.wikipedia.org/wiki/Autoencoder"
      ]
    }
  ]
}